{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75e564d",
   "metadata": {},
   "source": [
    "\n",
    "# Objetivo 2: Generación de modelos\n",
    "\n",
    "Pipeline completo para la predicción del crecimiento de datos de biodiversidad en GBIF.\n",
    "\n",
    "Este script implementa el flujo de trabajo de principio a fin para modelar datos de panel\n",
    "de series temporales, incluyendo:\n",
    "1.  Carga datos de PA_dataAnalysis y preparación\n",
    "2.  Ingeniería de características temporales (lags y ventanas móviles).\n",
    "3.  Un marco de validación cruzada robusto para series de tiempo (ventana expansiva).\n",
    "4.  Preprocesamiento (imputación y escalado) dentro del bucle de validación para evitar fuga de datos.\n",
    "5.  Entrenamiento y evaluación comparativa de cuatro modelos:\n",
    "    - Prophet.\n",
    "    - Random Forest.\n",
    "    - XGBoost.\n",
    "    - Red Neuronal LSTM (para modelado secuencial).\n",
    "6.  Selección del mejor modelo basado en métricas de rendimiento (MAE, RMSE, R²).\n",
    "7.  Reentrenamiento del modelo final y generación de pronósticos para Colombia hasta 2030\n",
    "    bajo dos escenarios de políticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d92da8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ricardoortiz/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/ricardoortiz/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1. IMPORTACIÓN DE LIBRERÍAS Y CONFIGURACIÓN INICIAL\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Preprocesamiento y modelado de Scikit-Learn\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Modelos especializados\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "\n",
    "\n",
    "# Configuraciones generales\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e0c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelado de Deep Learning con TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24978f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga de datos\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/rortizgeo/Maestria_CD_Proyecto-Aplicado/main/Data_final.csv\"\n",
    "Data_final = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cadacbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Paso 2: Realizando ingeniería de características temporales (versión combinada)...\n",
      "Ingeniería de características completada.\n",
      "   country  year  superficie_total_km2  areas_protegidas  pib_per_capita  \\\n",
      "0  Andorra  2007                 470.0               NaN    48336.228333   \n",
      "1  Andorra  2008                 470.0               NaN    49132.515708   \n",
      "2  Andorra  2009                 470.0               NaN    43975.018367   \n",
      "3  Andorra  2010                 470.0               NaN    42746.830953   \n",
      "4  Andorra  2011                 470.0               NaN    46657.156117   \n",
      "5  Andorra  2012                 470.0               NaN    41500.543579   \n",
      "6  Andorra  2013                 470.0               9.2    42470.316116   \n",
      "7  Andorra  2014                 470.0              18.2    44369.659691   \n",
      "8  Andorra  2015                 470.0              21.1    38654.934720   \n",
      "9  Andorra  2016                 470.0              21.1    40129.819201   \n",
      "\n",
      "   gasto_educacion_gobierno  gasto_educacion_pib  Overall score countryCode  \\\n",
      "0                  9.035916             2.104690            NaN          AD   \n",
      "1                 10.905499             2.873930            NaN          AD   \n",
      "2                  9.907326             3.142920            NaN          AD   \n",
      "3                  9.663179             2.976630            NaN          AD   \n",
      "4                  9.549792             2.987060            NaN          AD   \n",
      "5                  9.841614             2.565779            NaN          AD   \n",
      "6                  6.195530             2.506160            NaN          AD   \n",
      "7                 13.315210             3.074210            NaN          AD   \n",
      "8                 10.442810             3.280350            NaN          AD   \n",
      "9                  9.990980             3.237070            NaN          AD   \n",
      "\n",
      "                  region  ... gasto_educacion_pib_lag9  \\\n",
      "0  Europe & Central Asia  ...                      NaN   \n",
      "1  Europe & Central Asia  ...                      NaN   \n",
      "2  Europe & Central Asia  ...                      NaN   \n",
      "3  Europe & Central Asia  ...                      NaN   \n",
      "4  Europe & Central Asia  ...                      NaN   \n",
      "5  Europe & Central Asia  ...                      NaN   \n",
      "6  Europe & Central Asia  ...                      NaN   \n",
      "7  Europe & Central Asia  ...                      NaN   \n",
      "8  Europe & Central Asia  ...                      NaN   \n",
      "9  Europe & Central Asia  ...                  2.10469   \n",
      "\n",
      "   gasto_educacion_pib_lag10  gasto_educacion_pib_rollmean3  \\\n",
      "0                        NaN                            NaN   \n",
      "1                        NaN                            NaN   \n",
      "2                        NaN                            NaN   \n",
      "3                        NaN                       2.707180   \n",
      "4                        NaN                       2.997827   \n",
      "5                        NaN                       3.035537   \n",
      "6                        NaN                       2.843156   \n",
      "7                        NaN                       2.686333   \n",
      "8                        NaN                       2.715383   \n",
      "9                        NaN                       2.953573   \n",
      "\n",
      "   gasto_educacion_pib_rollstd3  gasto_educacion_pib_rollmean5  \\\n",
      "0                           NaN                            NaN   \n",
      "1                           NaN                            NaN   \n",
      "2                           NaN                            NaN   \n",
      "3                      0.538827                            NaN   \n",
      "4                      0.135742                            NaN   \n",
      "5                      0.093143                       2.817046   \n",
      "6                      0.240272                       2.909264   \n",
      "7                      0.262138                       2.835710   \n",
      "8                      0.312180                       2.821968   \n",
      "9                      0.400946                       2.882712   \n",
      "\n",
      "   gasto_educacion_pib_rollstd5  gasto_educacion_pib_rollmean7  \\\n",
      "0                           NaN                            NaN   \n",
      "1                           NaN                            NaN   \n",
      "2                           NaN                            NaN   \n",
      "3                           NaN                            NaN   \n",
      "4                           NaN                            NaN   \n",
      "5                      0.409650                            NaN   \n",
      "6                      0.214718                            NaN   \n",
      "7                      0.282227                       2.736738   \n",
      "8                      0.264655                       2.875241   \n",
      "9                      0.334632                       2.933301   \n",
      "\n",
      "   gasto_educacion_pib_rollstd7  gasto_educacion_pib_rollmean10  \\\n",
      "0                           NaN                             NaN   \n",
      "1                           NaN                             NaN   \n",
      "2                           NaN                             NaN   \n",
      "3                           NaN                             NaN   \n",
      "4                           NaN                             NaN   \n",
      "5                           NaN                             NaN   \n",
      "6                           NaN                             NaN   \n",
      "7                      0.361914                             NaN   \n",
      "8                      0.246986                             NaN   \n",
      "9                      0.290553                             NaN   \n",
      "\n",
      "   gasto_educacion_pib_rollstd10  \n",
      "0                            NaN  \n",
      "1                            NaN  \n",
      "2                            NaN  \n",
      "3                            NaN  \n",
      "4                            NaN  \n",
      "5                            NaN  \n",
      "6                            NaN  \n",
      "7                            NaN  \n",
      "8                            NaN  \n",
      "9                            NaN  \n",
      "\n",
      "[10 rows x 88 columns]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2. INGENIERÍA DE CARACTERÍSTICAS TEMPORALES\n",
    "# =============================================================================\n",
    "print(\"\\nPaso 2: Realizando ingeniería de características temporales (versión combinada)...\")\n",
    "\n",
    "\"\"\"\n",
    "    Crea características de retardo (lag) y de ventana móvil para el conjunto de datos preparado previamente.\n",
    "    Las operaciones se agrupan por país para evitar la fuga de datos entre series.\n",
    "\"\"\"\n",
    "\n",
    "TARGET = 'occurrenceCount_publisher'\n",
    "\n",
    "def create_temporal_features_safe(data, features_to_lag, lags=[1, 2, 3,4,5,6,7,8,9,10], roll_windows=[3, 5, 7, 10]):\n",
    "    \"\"\"\n",
    "    Genera características temporales (lags y rolling) por país,\n",
    "    evitando fuga de datos con shift(1).\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Dataset con al menos 'country' y variables numéricas.\n",
    "    features_to_lag : list\n",
    "        Lista de columnas numéricas a transformar.\n",
    "    lags : list\n",
    "        Lista de retardos (ej. [1,2]).\n",
    "    roll_windows : list\n",
    "        Lista de ventanas móviles (ej. [3,5]).\n",
    "        \n",
    "    Retorna\n",
    "    -------\n",
    "    DataFrame con nuevas columnas de lags y rolling.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_copy = data.copy()\n",
    "    \n",
    "    for feature in features_to_lag:\n",
    "        for lag in lags:\n",
    "            df_copy[f'{feature}_lag{lag}'] = (\n",
    "                df_copy.groupby('country')[feature].shift(lag)\n",
    "            )\n",
    "        for w in roll_windows:\n",
    "            df_copy[f'{feature}_rollmean{w}'] = (\n",
    "                df_copy.groupby('country')[feature].shift(1).rolling(w).mean()\n",
    "            )\n",
    "            df_copy[f'{feature}_rollstd{w}'] = (\n",
    "                df_copy.groupby('country')[feature].shift(1).rolling(w).std()\n",
    "            )\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# Uso del código\n",
    "# ===========================\n",
    "# Ejemplo: variables socioeconómicas y target\n",
    "features_to_lag = [\n",
    "    \"occurrenceCount_publisher\", \"pib_per_capita\",\n",
    "    \"gasto_educacion_gobierno\", \"gasto_educacion_pib\"\n",
    "]\n",
    "\n",
    "# Crear dataset con nuevas features\n",
    "df_featured = create_temporal_features_safe(\n",
    "    Data_final,\n",
    "    features_to_lag=features_to_lag,\n",
    "    lags=[1, 2,3,4,5,6,7,8,9,10],\n",
    "    roll_windows=[3, 5, 7, 10]\n",
    ")\n",
    "\n",
    "print(\"Ingeniería de características completada.\")\n",
    "print(df_featured.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfbcc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. PREPARACIÓN PARA EL MODELADO Y VALIDACIÓN\n",
    "# =============================================================================\n",
    "print(\"\\nPaso 3: Preparando el marco de validación y los datos para el modelado...\")\n",
    "\n",
    "# Definir variable objetivo\n",
    "TARGET = 'occurrenceCount_publisher'\n",
    "\n",
    "# Definir variables predictoras (ajusta según tus columnas disponibles)\n",
    "features = [\n",
    "    'PC1', 'PC2', 'pib_per_capita', 'gasto_educacion_gobierno',\n",
    "    'gasto_educacion_pib', 'superficie_total_km2', 'areas_protegidas',\n",
    "    f\"{TARGET}_lag1\", f\"{TARGET}_lag2\", f\"{TARGET}_rollmean3\", f\"{TARGET}_rollstd3\"\n",
    "]\n",
    "\n",
    "# Filtrar las variables que realmente existen en el DataFrame\n",
    "features = [f for f in features if f in df_featured.columns]\n",
    "\n",
    "# Definir X (predictoras) e y (objetivo)\n",
    "X = df_featured[features].copy()\n",
    "y = df_featured[TARGET].copy()\n",
    "\n",
    "# Configurar validación cruzada para series de tiempo\n",
    "n_splits = 5  # número de pliegues\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "# Diccionario para almacenar resultados\n",
    "results = {\n",
    "    'Prophet': None,\n",
    "    'RandomForest': None,\n",
    "    'XGBoost': None,\n",
    "    'LSTM': None\n",
    "}\n",
    "\n",
    "print(\"Features seleccionadas:\", features)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4ed319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. BUCLE DE ENTRENAMIENTO Y EVALUACIÓN DE MODELOS\n",
    "# =============================================================================\n",
    "print(\"\\nPaso 4: Iniciando el bucle de entrenamiento y validación de modelos...\")\n",
    "\n",
    "for fold, (train_year_idx, test_year_idx) in enumerate(tscv.split(unique_years)):\n",
    "    print(f\"\\n===== FOLD {fold + 1}/{n_splits} =====\")\n",
    "    \n",
    "    # Identificar los años de entrenamiento y prueba\n",
    "    train_years = unique_years[train_year_idx]\n",
    "    test_years = unique_years[test_year_idx]\n",
    "    print(f\"Años de entrenamiento: {train_years.min()} - {train_years.max()}\")\n",
    "    print(f\"Años de prueba: {test_years.min()} - {test_years.max()}\")\n",
    "\n",
    "    # Dividir los datos en entrenamiento y prueba según los años\n",
    "    train_indices = X[X['year'].isin(train_years)].index\n",
    "    test_indices = X[X['year'].isin(test_years)].index\n",
    "    \n",
    "    X_train, X_test = X.loc[train_indices], X.loc[test_indices]\n",
    "    y_train, y_test = y.loc[train_indices], y.loc[test_indices]\n",
    "\n",
    "    # --- Preprocesamiento DENTRO del bucle para evitar fuga de datos ---\n",
    "    # Guardar los nombres de las columnas y los países para después\n",
    "    X_train_countries = X_train['country']\n",
    "    X_test_countries = X_test['country']\n",
    "    X_train_columns = X_train.drop(columns=['country']).columns\n",
    "    \n",
    "    # Separar 'country' antes de imputar y escalar\n",
    "    X_train_numeric = X_train.drop(columns=['country'])\n",
    "    X_test_numeric = X_test.drop(columns=['country'])\n",
    "\n",
    "    # Imputación de valores faltantes\n",
    "    imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "    X_train_imputed = imputer.fit_transform(X_train_numeric)\n",
    "    X_test_imputed = imputer.transform(X_test_numeric)\n",
    "\n",
    "    # Escalado de características\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "    X_test_scaled = scaler.transform(X_test_imputed)\n",
    "    \n",
    "    # Convertir de nuevo a DataFrame para facilidad de uso\n",
    "    X_train_processed = pd.DataFrame(X_train_scaled, columns=X_train_columns, index=X_train.index)\n",
    "    X_test_processed = pd.DataFrame(X_test_scaled, columns=X_train_columns, index=X_test.index)\n",
    "    \n",
    "    # Añadir de nuevo la columna 'country'\n",
    "    X_train_processed['country'] = X_train_countries\n",
    "    X_test_processed['country'] = X_test_countries\n",
    "\n",
    "    # --- Modelo 1: SARIMAX (Línea Base Estadística) ---\n",
    "    print(\"Entrenando SARIMAX...\")\n",
    "    sarimax_preds =\n",
    "    y_test_sarimax =\n",
    "    \n",
    "    # Se ajusta un modelo por cada país en el conjunto de prueba\n",
    "    for country in tqdm(X_test_processed['country'].unique(), desc=\"SARIMAX per country\"):\n",
    "        train_country_data = df_featured[df_featured['country'] == country][df_featured['year'].isin(train_years)]\n",
    "        test_country_data = df_featured[df_featured['country'] == country][df_featured['year'].isin(test_years)]\n",
    "        \n",
    "        if not train_country_data.empty and not test_country_data.empty:\n",
    "            endog = train_country_data\n",
    "            exog_cols = [c for c in features if c not in ['year', 'country']]\n",
    "            exog_train = train_country_data[exog_cols]\n",
    "            exog_test = test_country_data[exog_cols]\n",
    "            \n",
    "            try:\n",
    "                # Usamos un orden simple (p,d,q)=(1,1,1) para la demostración\n",
    "                model = SARIMAX(endog, exog=exog_train, order=(1, 1, 1), seasonal_order=(0, 0, 0, 0))\n",
    "                results_sarimax = model.fit(disp=False)\n",
    "                forecast = results_sarimax.get_forecast(steps=len(test_country_data), exog=exog_test)\n",
    "                sarimax_preds.extend(forecast.predicted_mean.values)\n",
    "                y_test_sarimax.extend(test_country_data.values)\n",
    "            except Exception as e:\n",
    "                # Si un modelo falla, predecimos la última observación conocida\n",
    "                sarimax_preds.extend([endog.iloc[-1]] * len(test_country_data))\n",
    "                y_test_sarimax.extend(test_country_data.values)\n",
    "\n",
    "    if y_test_sarimax:\n",
    "        mae = mean_absolute_error(y_test_sarimax, sarimax_preds)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_sarimax, sarimax_preds))\n",
    "        r2 = r2_score(y_test_sarimax, sarimax_preds)\n",
    "        results.append({'MAE': mae, 'RMSE': rmse, 'R2': r2})\n",
    "        print(f\"SARIMAX - MAE: {mae:.2f}, RMSE: {rmse:.2f}, R2: {r2:.2f}\")\n",
    "\n",
    "    # --- Modelos de Machine Learning (usando datos procesados sin 'country') ---\n",
    "    X_train_ml = X_train_processed.drop(columns=['country'])\n",
    "    X_test_ml = X_test_processed.drop(columns=['country'])\n",
    "\n",
    "    # --- Modelo 2: Random Forest ---\n",
    "    print(\"Entrenando Random Forest...\")\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf_model.fit(X_train_ml, y_train)\n",
    "    rf_preds = rf_model.predict(X_test_ml)\n",
    "    mae = mean_absolute_error(y_test, rf_preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, rf_preds))\n",
    "    r2 = r2_score(y_test, rf_preds)\n",
    "    results.append({'MAE': mae, 'RMSE': rmse, 'R2': r2})\n",
    "    print(f\"Random Forest - MAE: {mae:.2f}, RMSE: {rmse:.2f}, R2: {r2:.2f}\")\n",
    "\n",
    "    # --- Modelo 3: XGBoost ---\n",
    "    print(\"Entrenando XGBoost...\")\n",
    "    xgb_model = xgb.XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    xgb_model.fit(X_train_ml, y_train)\n",
    "    xgb_preds = xgb_model.predict(X_test_ml)\n",
    "    mae = mean_absolute_error(y_test, xgb_preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, xgb_preds))\n",
    "    r2 = r2_score(y_test, xgb_preds)\n",
    "    results.append({'MAE': mae, 'RMSE': rmse, 'R2': r2})\n",
    "    print(f\"XGBoost - MAE: {mae:.2f}, RMSE: {rmse:.2f}, R2: {r2:.2f}\")\n",
    "\n",
    "    # --- Modelo 4: LSTM ---\n",
    "    print(\"Entrenando LSTM...\")\n",
    "    \n",
    "    def create_lstm_dataset(X, y, countries, look_back=3):\n",
    "        dataX, dataY =,\n",
    "        for country in countries.unique():\n",
    "            X_country = X[countries == country]\n",
    "            y_country = y[countries == country]\n",
    "            if len(X_country) > look_back:\n",
    "                for i in range(len(X_country) - look_back):\n",
    "                    a = X_country.iloc[i:(i + look_back)].values\n",
    "                    dataX.append(a)\n",
    "                    dataY.append(y_country.iloc[i + look_back])\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "\n",
    "    look_back = 3\n",
    "    X_train_lstm, y_train_lstm = create_lstm_dataset(X_train_ml, y_train, X_train_processed['country'], look_back)\n",
    "    X_test_lstm, y_test_lstm = create_lstm_dataset(X_test_ml, y_test, X_test_processed['country'], look_back)\n",
    "\n",
    "    if X_train_lstm.shape > 0 and X_test_lstm.shape > 0:\n",
    "        # Definir la arquitectura del modelo LSTM\n",
    "        lstm_model = Sequential(, X_train_lstm.shape[2])),\n",
    "            Dropout(0.2),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        \n",
    "        # Entrenar el modelo\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        lstm_model.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=32, \n",
    "                       validation_data=(X_test_lstm, y_test_lstm), \n",
    "                       callbacks=[early_stopping], verbose=0)\n",
    "        \n",
    "        # Realizar predicciones\n",
    "        lstm_preds = lstm_model.predict(X_test_lstm).flatten()\n",
    "        \n",
    "        mae = mean_absolute_error(y_test_lstm, lstm_preds)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_lstm, lstm_preds))\n",
    "        r2 = r2_score(y_test_lstm, lstm_preds)\n",
    "        results.append({'MAE': mae, 'RMSE': rmse, 'R2': r2})\n",
    "        print(f\"LSTM - MAE: {mae:.2f}, RMSE: {rmse:.2f}, R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6. ANÁLISIS COMPARATIVO Y SELECCIÓN DEL MODELO\n",
    "# =============================================================================\n",
    "print(\"\\nPaso 5: Analizando y comparando los resultados de los modelos...\")\n",
    "\n",
    "# Convertir los resultados a un DataFrame para fácil visualización\n",
    "summary_list =\n",
    "for model_name, metrics_list in results.items():\n",
    "    if metrics_list:\n",
    "        df_metrics = pd.DataFrame(metrics_list)\n",
    "        summary_list.append({\n",
    "            'Model': model_name,\n",
    "            'MAE_mean': df_metrics['MAE'].mean(),\n",
    "            'MAE_std': df_metrics['MAE'].std(),\n",
    "            'RMSE_mean': df_metrics.mean(),\n",
    "            'RMSE_std': df_metrics.std(),\n",
    "            'R2_mean': df_metrics.mean(),\n",
    "            'R2_std': df_metrics.std()\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_list).set_index('Model')\n",
    "print(\"\\nResumen del rendimiento de los modelos (promedio de los pliegues de CV):\")\n",
    "print(summary_df)\n",
    "\n",
    "# Seleccionar el mejor modelo (basado en el RMSE más bajo)\n",
    "best_model_name = summary_df.idxmin()\n",
    "print(f\"\\nMejor modelo seleccionado: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfae2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 7. REENTRENAMIENTO DEL MODELO FINAL Y PRONÓSTICO PARA COLOMBIA\n",
    "# =============================================================================\n",
    "print(f\"\\nPaso 6: Reentrenando el modelo {best_model_name} con todos los datos...\")\n",
    "\n",
    "# Preparar todos los datos para el reentrenamiento\n",
    "X_full_numeric = X.drop(columns=['country'])\n",
    "imputer_final = IterativeImputer(max_iter=10, random_state=42)\n",
    "X_full_imputed = imputer_final.fit_transform(X_full_numeric)\n",
    "scaler_final = StandardScaler()\n",
    "X_full_scaled = scaler_final.fit_transform(X_full_imputed)\n",
    "X_full_processed = pd.DataFrame(X_full_scaled, columns=X_full_numeric.columns, index=X.index)\n",
    "\n",
    "# Reentrenar el modelo XGBoost\n",
    "final_model = xgb.XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "final_model.fit(X_full_processed, y)\n",
    "\n",
    "print(\"Modelo final entrenado. Generando pronósticos para Colombia...\")\n",
    "\n",
    "# --- Creación de escenarios futuros para Colombia ---\n",
    "colombia_last_data = df_featured[df_featured['country'] == 'Colombia'].iloc[-1]\n",
    "future_years = range(2023, 2031)\n",
    "future_df = pd.DataFrame()\n",
    "\n",
    "for year in future_years:\n",
    "    future_row = colombia_last_data.copy()\n",
    "    future_row['year'] = year\n",
    "    future_df = pd.concat(, ignore_index=True)\n",
    "\n",
    "# Escenario A: \"Business as Usual\" (extrapolación simple)\n",
    "for col in:\n",
    "    # Simple extrapolación lineal para la tendencia\n",
    "    last_val = colombia_last_data[col]\n",
    "    trend = (colombia_last_data[col] - df_featured[df_featured['country'] == 'Colombia'][col].iloc[-5:].mean()) / 5\n",
    "    future_df[col] = [last_val + trend * i for i in range(1, len(future_years) + 1)]\n",
    "\n",
    "# Escenario B: \"Inversión Estratégica\" (aumento del 10% en gasto en educación)\n",
    "future_df_optimistic = future_df.copy()\n",
    "future_df_optimistic['gasto_educacion_pib'] *= 1.10\n",
    "\n",
    "# Función para predecir recursivamente\n",
    "def generate_forecast(model, initial_data, future_template, scaler, imputer):\n",
    "    history = initial_data.copy()\n",
    "    predictions =\n",
    "    \n",
    "    for i in range(len(future_template)):\n",
    "        # Preparar la fila para la predicción actual\n",
    "        current_step_features = future_template.iloc[[i]]\n",
    "        \n",
    "        # Actualizar lags y rolling stats con el último dato conocido (de history)\n",
    "        last_known = history.iloc[-1]\n",
    "        for feature in features_to_lag:\n",
    "            current_step_features[f'{feature}_lag_1'] = last_known[feature]\n",
    "            # Para rolling stats, usamos los últimos datos de history\n",
    "            rolling_window = pd.concat()])[feature]\n",
    "            current_step_features[f'{feature}_rolling_mean_3'] = rolling_window.mean()\n",
    "            current_step_features[f'{feature}_rolling_std_3'] = rolling_window.std()\n",
    "\n",
    "        # Preprocesar la fila\n",
    "        current_step_numeric = current_step_features[X_full_numeric.columns]\n",
    "        current_step_imputed = imputer.transform(current_step_numeric)\n",
    "        current_step_scaled = scaler.transform(current_step_imputed)\n",
    "        \n",
    "        # Predecir\n",
    "        prediction = model.predict(current_step_scaled)\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "        # Actualizar 'history' con la nueva predicción para el siguiente paso\n",
    "        new_row = current_step_features.copy()\n",
    "        new_row = prediction\n",
    "        history = pd.concat([history, new_row], ignore_index=True)\n",
    "        \n",
    "    return predictions\n",
    "\n",
    "# Generar pronósticos para ambos escenarios\n",
    "forecast_base = generate_forecast(final_model, df_featured[df_featured['country'] == 'Colombia'], future_df, scaler_final, imputer_final)\n",
    "forecast_optimistic = generate_forecast(final_model, df_featured[df_featured['country'] == 'Colombia'], future_df_optimistic, scaler_final, imputer_final)\n",
    "\n",
    "# --- Visualización de los resultados ---\n",
    "plt.figure(figsize=(18, 9))\n",
    "# Datos históricos\n",
    "plt.plot(df_featured[df_featured['country'] == 'Colombia']['year'], \n",
    "         df_featured[df_featured['country'] == 'Colombia'], \n",
    "         label='Histórico - SiB Colombia', color='black', marker='o')\n",
    "# Pronóstico Base\n",
    "plt.plot(future_years, forecast_base, label='Pronóstico Base (\"Business as Usual\")', color='blue', marker='x', linestyle='--')\n",
    "# Pronóstico Optimista\n",
    "plt.plot(future_years, forecast_optimistic, label='Pronóstico Optimista (↑ Gasto Educación)', color='green', marker='^', linestyle='--')\n",
    "\n",
    "plt.title('Pronóstico de Crecimiento de Publicación de Datos para SiB Colombia (2023-2030)', fontsize=16)\n",
    "plt.xlabel('Año', fontsize=12)\n",
    "plt.ylabel('Número de Registros Publicados (occurrenceCount_publisher)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nProceso completado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
