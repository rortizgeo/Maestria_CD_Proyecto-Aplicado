{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75e564d",
   "metadata": {},
   "source": [
    "\n",
    "# Objetivo 2: Generación de modelos\n",
    "\n",
    "Pipeline completo para la predicción del crecimiento de datos de biodiversidad en GBIF.\n",
    "\n",
    "Este script implementa el flujo de trabajo de principio a fin para modelar datos de panel\n",
    "de series temporales, incluyendo:\n",
    "1.  Carga datos de PA_dataAnalysis y preparación\n",
    "2.  Ingeniería de características temporales (lags y ventanas móviles).\n",
    "3.  Un marco de validación cruzada robusto para series de tiempo (ventana expansiva).\n",
    "4.  Preprocesamiento (imputación y escalado) dentro del bucle de validación para evitar fuga de datos.\n",
    "5.  Entrenamiento y evaluación comparativa de cuatro modelos:\n",
    "    - Prophet.\n",
    "    - Random Forest.\n",
    "    - XGBoost.\n",
    "    - Red Neuronal LSTM (para modelado secuencial).\n",
    "    - INCLUIR SARIMAX DE TODOS MODOS, INTENTAR HACER UNA TRANSFORMACIÓN LOGARÍTMICA, SE PUEDE PONER SIN LA VALIDACIÓN DE SUPUESTOS. TENER CUIDADO CON EL CROSS VALIDATION.\n",
    "6.  Selección del mejor modelo basado en métricas de rendimiento (MAE, RMSE, R²).\n",
    "7.  Reentrenamiento del modelo final y generación de pronósticos para Colombia hasta 2030\n",
    "    bajo dos escenarios de políticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8d92da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. IMPORTACIÓN DE LIBRERÍAS Y CONFIGURACIÓN INICIAL\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Preprocesamiento y modelado de Scikit-Learn\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "# Modelos especializados\n",
    "\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from prophet import Prophet\n",
    "\n",
    "# Configuraciones generales\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7bec6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelado de Deep Learning con TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24978f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga de datos\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/rortizgeo/Maestria_CD_Proyecto-Aplicado/main/Data_final.csv\"\n",
    "Data_final = pd.read_csv(url)\n",
    "\n",
    "# Convertir 'year' a formato de fecha para Prophet\n",
    "Data_final['ds'] = pd.to_datetime(Data_final['year'], format='%Y')\n",
    "\n",
    "# Ordenar los datos por país y año, es crucial para series de tiempo\n",
    "Data_final = Data_final.sort_values(by=['country', 'ds']).reset_index(drop=True) # Falta ajustar para que la fecha sea al 31 de Diciembre de cada año\n",
    "\n",
    "# Eliminación de columnas por tener muchos vacíos y no ser posible completarlas con imputación. (pensar en otras estrategias)\n",
    "columns_to_drop = ['Overall score', 'areas_protegidas']\n",
    "Data_final = Data_final.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126e13f3",
   "metadata": {},
   "source": [
    "Para aplicar modelos como Random Forest y XGBoost, es necesario agregar características de temporalidad en los datos, para lo cuál es necesario calcular retardos, que se deben aplicar teniendo en cuenta un análisis del ACF Y PACF, así como la incorporación de los tiempos del retardo como hiperparámetros. \n",
    "\n",
    "Los modelos basados en árboles como Random Forest y XGBoost no son conscientes de la secuencia temporal de los datos y no pueden \"extrapolar\" tendencias más allá de los valores que han visto en el entrenamiento. Por lo tanto, es necesario convertir la información temporal en características que el modelo pueda entender. La creación de retardos (lags) y estadísticas de ventana móvil es la técnica estándar para lograrlo. Se podría identificar el número de retardos como un hiperparámetro, guiado por análisis de ACF y PACF (Ver EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cadacbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Paso 2: Realizando ingeniería de características temporales...\n",
      "Ingeniería de características completada.\n",
      "Shape del dataset: (656, 81)\n",
      "Valores NaN restantes: 0\n",
      "\n",
      "Estadísticas de las nuevas características:\n",
      "       occurrenceCount_publisher_lag1  occurrenceCount_publisher_lag2  \\\n",
      "count                    6.560000e+02                    6.560000e+02   \n",
      "mean                     1.530224e+07                    1.257584e+07   \n",
      "std                      5.295431e+07                    4.383457e+07   \n",
      "min                      0.000000e+00                    0.000000e+00   \n",
      "25%                      1.549475e+04                    1.335000e+02   \n",
      "50%                      1.176419e+06                    5.515200e+05   \n",
      "75%                      9.340858e+06                    7.115654e+06   \n",
      "max                      7.401771e+08                    5.946568e+08   \n",
      "\n",
      "       occurrenceCount_publisher_lag3  occurrenceCount_publisher_lag4  \\\n",
      "count                    6.560000e+02                    6.560000e+02   \n",
      "mean                     1.024584e+07                    8.296004e+06   \n",
      "std                      3.656712e+07                    3.057768e+07   \n",
      "min                      0.000000e+00                    0.000000e+00   \n",
      "25%                      0.000000e+00                    0.000000e+00   \n",
      "50%                      2.662950e+05                    1.096710e+05   \n",
      "75%                      5.047951e+06                    3.175013e+06   \n",
      "max                      4.897051e+08                    3.528648e+08   \n",
      "\n",
      "       occurrenceCount_publisher_lag5  occurrenceCount_publisher_rollmean3  \\\n",
      "count                    6.560000e+02                         6.560000e+02   \n",
      "mean                     6.738803e+06                         1.668685e+07   \n",
      "std                      2.673301e+07                         5.368850e+07   \n",
      "min                      0.000000e+00                         0.000000e+00   \n",
      "25%                      0.000000e+00                         7.333842e+04   \n",
      "50%                      1.874800e+04                         1.624914e+06   \n",
      "75%                      2.448169e+06                         1.190595e+07   \n",
      "max                      3.442562e+08                         6.674169e+08   \n",
      "\n",
      "       occurrenceCount_publisher_rollstd3  \\\n",
      "count                        6.560000e+02   \n",
      "mean                         4.812063e+06   \n",
      "std                          2.360976e+07   \n",
      "min                          0.000000e+00   \n",
      "25%                          8.972601e+03   \n",
      "50%                          3.353990e+05   \n",
      "75%                          2.509022e+06   \n",
      "max                          5.233843e+08   \n",
      "\n",
      "       occurrenceCount_publisher_rollmean5  \\\n",
      "count                         6.560000e+02   \n",
      "mean                          1.657737e+07   \n",
      "std                           4.957963e+07   \n",
      "min                           0.000000e+00   \n",
      "25%                           1.419378e+05   \n",
      "50%                           2.011318e+06   \n",
      "75%                           1.261729e+07   \n",
      "max                           5.443510e+08   \n",
      "\n",
      "       occurrenceCount_publisher_rollstd5  \\\n",
      "count                        6.560000e+02   \n",
      "mean                         7.874283e+06   \n",
      "std                          2.826472e+07   \n",
      "min                          0.000000e+00   \n",
      "25%                          4.817769e+04   \n",
      "50%                          1.016754e+06   \n",
      "75%                          6.251451e+06   \n",
      "max                          3.898861e+08   \n",
      "\n",
      "       occurrenceCount_publisher_rollmean7  ...    PC2_lag2    PC2_lag3  \\\n",
      "count                         6.560000e+02  ...  656.000000  656.000000   \n",
      "mean                          1.649014e+07  ...    0.007352    0.014060   \n",
      "std                           4.648245e+07  ...    0.948922    0.917314   \n",
      "min                           0.000000e+00  ...   -3.186064   -3.186064   \n",
      "25%                           2.050516e+05  ...   -0.504833   -0.459020   \n",
      "50%                           2.304801e+06  ...   -0.003332    0.000000   \n",
      "75%                           1.425623e+07  ...    0.272011    0.237563   \n",
      "max                           4.764592e+08  ...    4.159860    4.159860   \n",
      "\n",
      "         PC2_lag4    PC2_lag5  PC2_rollmean3  PC2_rollstd3  PC2_rollmean5  \\\n",
      "count  656.000000  656.000000     656.000000    656.000000     656.000000   \n",
      "mean     0.018683    0.021782      -0.001020      0.142671      -0.001844   \n",
      "std      0.887733    0.853915       0.987812      0.280691       0.957563   \n",
      "min     -3.186064   -3.186064      -2.780765      0.000000      -2.474334   \n",
      "25%     -0.384310   -0.338562      -0.558434      0.031109      -0.541590   \n",
      "50%      0.000000    0.000000      -0.160543      0.060561      -0.153593   \n",
      "75%      0.177390    0.147735       0.312491      0.136391       0.308020   \n",
      "max      4.159860    4.159860       4.068705      2.929510       4.011364   \n",
      "\n",
      "       PC2_rollstd5  PC2_rollmean7  PC2_rollstd7  \n",
      "count    656.000000     656.000000    656.000000  \n",
      "mean       0.216098      -0.003054      0.277044  \n",
      "std        0.326479       0.929837      0.360519  \n",
      "min        0.000000      -2.356562      0.000000  \n",
      "25%        0.051429      -0.530476      0.072177  \n",
      "50%        0.107991      -0.152354      0.152887  \n",
      "75%        0.239385       0.308718      0.292375  \n",
      "max        2.182902       3.981097      2.030050  \n",
      "\n",
      "[8 rows x 66 columns]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2. INGENIERÍA DE CARACTERÍSTICAS TEMPORALES (OPTIMIZADA)\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nPaso 2: Realizando ingeniería de características temporales...\")\n",
    "\n",
    "TARGET = 'occurrenceCount_publisher'\n",
    "\n",
    "def create_temporal_features_optimized(data, features_to_lag, \n",
    "                                     lags=[1, 2, 3, 4, 5], \n",
    "                                     roll_windows=[3, 5, 7],\n",
    "                                     fill_na=0):\n",
    "    \"\"\"\n",
    "    Genera características temporales y completa automáticamente con 0\n",
    "    los valores NaN generados, según la lógica del negocio.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Dataset con al menos 'country' y variables numéricas.\n",
    "    features_to_lag : list\n",
    "        Lista de columnas numéricas a transformar.\n",
    "    lags : list\n",
    "        Lista de retardos.\n",
    "    roll_windows : list\n",
    "        Lista de ventanas móviles.\n",
    "    fill_na : int/float\n",
    "        Valor para completar NaN (0 por defecto según lógica de negocio).\n",
    "        \n",
    "    Retorna\n",
    "    -------\n",
    "    DataFrame con nuevas características y NaN completados.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_copy = Data_final.copy()\n",
    "    \n",
    "    for feature in features_to_lag:\n",
    "        # Características de lag\n",
    "        for lag in lags:\n",
    "            lag_col = f'{feature}_lag{lag}'\n",
    "            df_copy[lag_col] = df_copy.groupby('country')[feature].shift(lag)\n",
    "            df_copy[lag_col] = df_copy[lag_col].fillna(fill_na)\n",
    "        \n",
    "        # Características de ventana móvil\n",
    "        for w in roll_windows:\n",
    "            # Rolling mean\n",
    "            mean_col = f'{feature}_rollmean{w}'\n",
    "            df_copy[mean_col] = (\n",
    "                df_copy.groupby('country')[feature]\n",
    "                .shift(1)\n",
    "                .rolling(window=w, min_periods=1)\n",
    "                .mean()\n",
    "            )\n",
    "            df_copy[mean_col] = df_copy[mean_col].fillna(fill_na)\n",
    "            \n",
    "            # Rolling std\n",
    "            std_col = f'{feature}_rollstd{w}'\n",
    "            df_copy[std_col] = (\n",
    "                df_copy.groupby('country')[feature]\n",
    "                .shift(1)\n",
    "                .rolling(window=w, min_periods=1)\n",
    "                .std()\n",
    "            )\n",
    "            df_copy[std_col] = df_copy[std_col].fillna(fill_na)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "# ===========================\n",
    "# Uso del código optimizado\n",
    "# ===========================\n",
    "\n",
    "# Aplicar rezagos en bloques. Se deben hacer modelos con diferentes rezagos. Tener en cuenta que se pierden observaciones. Tomar todas las X y rezagar todas y hasta 3 periodos. Si incluir y-1.\n",
    "\n",
    "features_to_lag = [\n",
    "    \"occurrenceCount_publisher\", \"pib_per_capita\",\n",
    "    \"gasto_educacion_gobierno\", \"gasto_educacion_pib\", \"PC1\", \"PC2\"\n",
    "]\n",
    "\n",
    "# Crear dataset con nuevas features (completando con 0)\n",
    "df_featured = create_temporal_features_optimized(\n",
    "    Data_final,\n",
    "    features_to_lag=features_to_lag,\n",
    "    lags=[1, 2, 3, 4, 5],  # Reducido para evitar overfitting\n",
    "    roll_windows=[3, 5, 7],  # Reducido para evitar overfitting\n",
    "    fill_na=0  # ¡IMPORTANTE! Completar con 0, en este caso mostraría que para ese año no hubo publicación de datos.\n",
    ")\n",
    "\n",
    "print(\"Ingeniería de características completada.\")\n",
    "print(f\"Shape del dataset: {df_featured.shape}\")\n",
    "print(f\"Valores NaN restantes: {df_featured.isnull().sum().sum()}\")\n",
    "\n",
    "# Mostrar estadísticas de las nuevas características\n",
    "print(\"\\nEstadísticas de las nuevas características:\")\n",
    "new_features = [col for col in df_featured.columns if any(x in col for x in ['_lag', '_roll'])]\n",
    "print(df_featured[new_features].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0b8e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de valores en características temporales:\n",
      "occurrenceCount_publisher_lag1: 18.8% ceros\n",
      "occurrenceCount_publisher_lag2: 25.0% ceros\n",
      "occurrenceCount_publisher_lag3: 31.2% ceros\n",
      "occurrenceCount_publisher_lag4: 37.5% ceros\n",
      "occurrenceCount_publisher_lag5: 43.8% ceros\n",
      "occurrenceCount_publisher_rollmean3: 9.9% ceros\n",
      "occurrenceCount_publisher_rollstd3: 15.4% ceros\n",
      "occurrenceCount_publisher_rollmean5: 5.9% ceros\n",
      "occurrenceCount_publisher_rollstd5: 7.6% ceros\n",
      "occurrenceCount_publisher_rollmean7: 3.7% ceros\n",
      "occurrenceCount_publisher_rollstd7: 4.3% ceros\n",
      "pib_per_capita_lag1: 6.2% ceros\n",
      "pib_per_capita_lag2: 12.5% ceros\n",
      "pib_per_capita_lag3: 18.8% ceros\n",
      "pib_per_capita_lag4: 25.0% ceros\n",
      "pib_per_capita_lag5: 31.2% ceros\n",
      "pib_per_capita_rollmean3: 0.2% ceros\n",
      "pib_per_capita_rollstd3: 0.3% ceros\n",
      "pib_per_capita_rollmean5: 0.2% ceros\n",
      "pib_per_capita_rollstd5: 0.3% ceros\n",
      "pib_per_capita_rollmean7: 0.2% ceros\n",
      "pib_per_capita_rollstd7: 0.3% ceros\n",
      "gasto_educacion_gobierno_lag1: 6.2% ceros\n",
      "gasto_educacion_gobierno_lag2: 12.5% ceros\n",
      "gasto_educacion_gobierno_lag3: 18.8% ceros\n",
      "gasto_educacion_gobierno_lag4: 25.0% ceros\n",
      "gasto_educacion_gobierno_lag5: 31.2% ceros\n",
      "gasto_educacion_gobierno_rollmean3: 0.2% ceros\n",
      "gasto_educacion_gobierno_rollstd3: 0.3% ceros\n",
      "gasto_educacion_gobierno_rollmean5: 0.2% ceros\n",
      "gasto_educacion_gobierno_rollstd5: 0.3% ceros\n",
      "gasto_educacion_gobierno_rollmean7: 0.2% ceros\n",
      "gasto_educacion_gobierno_rollstd7: 0.3% ceros\n",
      "gasto_educacion_pib_lag1: 6.2% ceros\n",
      "gasto_educacion_pib_lag2: 12.5% ceros\n",
      "gasto_educacion_pib_lag3: 18.8% ceros\n",
      "gasto_educacion_pib_lag4: 25.0% ceros\n",
      "gasto_educacion_pib_lag5: 31.2% ceros\n",
      "gasto_educacion_pib_rollmean3: 0.2% ceros\n",
      "gasto_educacion_pib_rollstd3: 0.3% ceros\n",
      "gasto_educacion_pib_rollmean5: 0.2% ceros\n",
      "gasto_educacion_pib_rollstd5: 0.3% ceros\n",
      "gasto_educacion_pib_rollmean7: 0.2% ceros\n",
      "gasto_educacion_pib_rollstd7: 0.3% ceros\n",
      "PC1_lag1: 6.2% ceros\n",
      "PC1_lag2: 12.5% ceros\n",
      "PC1_lag3: 18.8% ceros\n",
      "PC1_lag4: 25.0% ceros\n",
      "PC1_lag5: 31.2% ceros\n",
      "PC1_rollmean3: 0.2% ceros\n",
      "PC1_rollstd3: 0.3% ceros\n",
      "PC1_rollmean5: 0.2% ceros\n",
      "PC1_rollstd5: 0.3% ceros\n",
      "PC1_rollmean7: 0.2% ceros\n",
      "PC1_rollstd7: 0.3% ceros\n",
      "PC2_lag1: 6.2% ceros\n",
      "PC2_lag2: 12.5% ceros\n",
      "PC2_lag3: 18.8% ceros\n",
      "PC2_lag4: 25.0% ceros\n",
      "PC2_lag5: 31.2% ceros\n",
      "PC2_rollmean3: 0.2% ceros\n",
      "PC2_rollstd3: 0.3% ceros\n",
      "PC2_rollmean5: 0.2% ceros\n",
      "PC2_rollstd5: 0.3% ceros\n",
      "PC2_rollmean7: 0.2% ceros\n",
      "PC2_rollstd7: 0.3% ceros\n"
     ]
    }
   ],
   "source": [
    "# Verificar distribución de las nuevas features # AJUSTAR Y QUITAR FILAS EN VEZ DE LLENAR CON 0\n",
    "print(\"Distribución de valores en características temporales:\")\n",
    "for col in new_features:\n",
    "    zero_percentage = (df_featured[col] == 0).mean() * 100\n",
    "    print(f\"{col}: {zero_percentage:.1f}% ceros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfbcc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Paso 3: Preparando el marco de validación y los datos para el modelado...\n",
      "\n",
      "Features numéricas: ['PC1', 'PC2', 'pib_per_capita', 'gasto_educacion_gobierno', 'gasto_educacion_pib', 'superficie_total_km2', 'occurrenceCount_publisher_lag1', 'occurrenceCount_publisher_lag2', 'occurrenceCount_publisher_lag3', 'occurrenceCount_publisher_lag4', 'occurrenceCount_publisher_lag5', 'occurrenceCount_publisher_rollmean3', 'occurrenceCount_publisher_rollstd3', 'occurrenceCount_publisher_rollmean5', 'occurrenceCount_publisher_rollstd5', 'occurrenceCount_publisher_rollmean7', 'occurrenceCount_publisher_rollstd7']\n",
      "Features categóricas: ['country', 'region', 'incomeLevel']\n",
      "Features de fecha: []\n",
      "\n",
      "Años disponibles: [2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020\n",
      " 2021 2022]\n",
      "Se usará TimeSeriesSplit con 5 folds.\n",
      "Features seleccionadas: ['PC1', 'PC2', 'pib_per_capita', 'gasto_educacion_gobierno', 'gasto_educacion_pib', 'superficie_total_km2', 'country', 'region', 'incomeLevel', 'occurrenceCount_publisher_lag1', 'occurrenceCount_publisher_lag2', 'occurrenceCount_publisher_lag3', 'occurrenceCount_publisher_lag4', 'occurrenceCount_publisher_lag5', 'occurrenceCount_publisher_rollmean3', 'occurrenceCount_publisher_rollstd3', 'occurrenceCount_publisher_rollmean5', 'occurrenceCount_publisher_rollstd5', 'occurrenceCount_publisher_rollmean7', 'occurrenceCount_publisher_rollstd7']\n",
      "X shape: (656, 20)\n",
      "y shape: (656,)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3. PREPARACIÓN PARA EL MODELADO Y VALIDACIÓN\n",
    "# =============================================================================\n",
    "print(\"\\nPaso 3: Preparando el marco de validación y los datos para el modelado...\")\n",
    "\n",
    "# Definir variable objetivo\n",
    "TARGET = 'occurrenceCount_publisher'\n",
    "\n",
    "# Definir variables predictoras (Decidir con Daniel cuáles usar basándose en EDA y disponibilidad. Preguntar si es posible usar todas sin complejizar el modelo) # ANALISIS DE CORRELACIONES CRUZADAS\n",
    "features = [\n",
    "    'PC1', 'PC2', 'pib_per_capita', 'gasto_educacion_gobierno',\n",
    "    'gasto_educacion_pib', 'superficie_total_km2',\n",
    "    \"country\", \"region\", \"incomeLevel\",\n",
    "    f\"{TARGET}_lag1\", f\"{TARGET}_lag2\", f\"{TARGET}_lag3\", f\"{TARGET}_lag4\", f\"{TARGET}_lag5\",\n",
    "    f\"{TARGET}_rollmean3\", f\"{TARGET}_rollstd3\", f\"{TARGET}_rollmean5\", f\"{TARGET}_rollstd5\",\n",
    "    f\"{TARGET}_rollmean7\", f\"{TARGET}_rollstd7\"\n",
    "    ]\n",
    "\n",
    "# Filtrar las variables que realmente existen en el DataFrame\n",
    "features = [f for f in features if f in df_featured.columns]\n",
    "\n",
    "# Separar tipos de columnas\n",
    "cat_cols  = [c for c in features if c in ['country', 'region', 'incomeLevel']]\n",
    "date_cols = [c for c in features if c == 'ds']\n",
    "num_cols  = [c for c in features if c not in cat_cols + date_cols]\n",
    "\n",
    "print(\"\\nFeatures numéricas:\", num_cols)\n",
    "print(\"Features categóricas:\", cat_cols)\n",
    "print(\"Features de fecha:\", date_cols)\n",
    "\n",
    "\n",
    "# Definir X (predictoras) y (objetivo)\n",
    "X = df_featured[features].copy()\n",
    "y = df_featured[TARGET].copy()\n",
    "\n",
    "# Configurar validación cruzada para series de tiempo\n",
    "n_splits = 5  # número de pliegues\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "# Extraer años únicos (ordenados) para controlar los folds\n",
    "unique_years = df_featured['year'].unique()\n",
    "unique_years.sort()\n",
    "print(f\"\\nAños disponibles: {unique_years}\")\n",
    "print(f\"Se usará TimeSeriesSplit con {n_splits} folds.\")\n",
    "\n",
    "# Diccionario para almacenar resultados (LIstas por modelo)\n",
    "results = {\n",
    "    'Prophet': [],\n",
    "    'RandomForest':[],\n",
    "    'XGBoost': [],\n",
    "    'LSTM': []\n",
    "}\n",
    "\n",
    "print(\"Features seleccionadas:\", features)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a2e95c",
   "metadata": {},
   "source": [
    "# Pruebas sin optimización de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "103208cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. CREACIÓN DE SECUENCIAS Y FUNCIONES DE MODELOS\n",
    "# =============================================================================\n",
    "\n",
    "def create_lstm_sequences_global(df, features, target, look_back=3):\n",
    "    \"\"\"\n",
    "    Crea secuencias LSTM para todos los países antes del split train/test.\n",
    "    Retorna X_seq, y_seq, years, countries (alineados).\n",
    "    \"\"\"\n",
    "    X_seq, y_seq, years, countries = [], [], [], []\n",
    "\n",
    "    for country in df['country'].unique():\n",
    "        df_country = df[df['country'] == country].sort_values('year')\n",
    "\n",
    "        # Extraer features y target como float32\n",
    "        X_country = df_country[features].values.astype(np.float32)\n",
    "        y_country = df_country[target].values.astype(np.float32)\n",
    "        years_country = df_country['year'].values\n",
    "\n",
    "        if len(X_country) > look_back:\n",
    "            for i in range(len(X_country) - look_back):\n",
    "                X_seq.append(X_country[i:(i + look_back)])\n",
    "                y_seq.append(y_country[i + look_back])\n",
    "                years.append(years_country[i + look_back])\n",
    "                countries.append(country)\n",
    "\n",
    "    return (\n",
    "        np.array(X_seq, dtype=np.float32),\n",
    "        np.array(y_seq, dtype=np.float32),\n",
    "        np.array(years),\n",
    "        np.array(countries),\n",
    "    )\n",
    "\n",
    "\n",
    "# ---- Modelos ----\n",
    "def train_random_forest(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Entrena un Random Forest Regressor y devuelve valores reales y predicciones.\n",
    "    \"\"\"\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        min_samples_leaf=3\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    return y_test, rf.predict(X_test)\n",
    "\n",
    "\n",
    "def train_xgboost(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Entrena un XGBoost Regressor y devuelve valores reales y predicciones.\n",
    "    \"\"\"\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return y_test, model.predict(X_test)\n",
    "\n",
    "\n",
    "def train_lstm(X_train, y_train, X_test, y_test, look_back):\n",
    "    \"\"\"\n",
    "    Entrena una LSTM básica y devuelve valores reales y predicciones.\n",
    "    \"\"\"\n",
    "    # Asegurar tipos correctos\n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    y_train = np.asarray(y_train, dtype=np.float32)\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    y_test = np.asarray(y_test, dtype=np.float32)\n",
    "\n",
    "    # Evitar entrenar si no hay suficientes datos\n",
    "    if X_train.shape[0] == 0 or X_test.shape[0] == 0:\n",
    "        return None, None\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(\n",
    "            50,\n",
    "            activation='relu',\n",
    "            input_shape=(look_back, X_train.shape[2])\n",
    "        ),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "\n",
    "    # Entrenar con early stopping opcional\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=16, verbose=0)\n",
    "\n",
    "    return y_test, model.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "\n",
    "def train_prophet(df, train_years, test_years, target, regressors=None):\n",
    "    # Base Prophet dataframe\n",
    "    prophet_df = df[['ds', target, 'year']].rename(columns={target: 'y'})\n",
    "    \n",
    "    if regressors:\n",
    "        for r in regressors:\n",
    "            if r in df.columns:\n",
    "                prophet_df[r] = df[r]\n",
    "\n",
    "    # Dividir train/test\n",
    "    prophet_train = prophet_df[prophet_df['year'].isin(train_years)]\n",
    "    prophet_test = prophet_df[prophet_df['year'].isin(test_years)]\n",
    "\n",
    "    # Crear modelo\n",
    "    m = Prophet(yearly_seasonality=True, daily_seasonality=False)\n",
    "    if regressors:\n",
    "        for r in regressors:\n",
    "            if r in prophet_df.columns:\n",
    "                m.add_regressor(r)\n",
    "\n",
    "    # Entrenar\n",
    "    m.fit(prophet_train)\n",
    "\n",
    "    # Generar predicciones\n",
    "    forecast = m.predict(prophet_test[['ds'] + (regressors or [])])\n",
    "\n",
    "    return prophet_test['y'].values, forecast['yhat'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4e72d49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 1/5 =====\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 12:35:26.503132: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-12 12:35:26.684366: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-12 12:35:30.863810: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "12:35:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:35:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 2/5 =====\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 12:35:32.225618: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-12 12:35:32.400323: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-12 12:35:38.090298: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "12:35:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:35:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 3/5 =====\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 12:35:39.467136: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-12 12:35:39.625889: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-12 12:35:47.108440: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "12:35:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:35:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 4/5 =====\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 12:35:48.435564: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-12 12:35:48.599590: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-12 12:35:58.289794: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "12:35:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:35:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 5/5 =====\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 12:35:59.633281: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-12 12:35:59.792810: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-12 12:36:11.138915: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "12:36:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:36:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 5. EJECUCIÓN DE MODELOS CON CROSS-VALIDATION (MEJORADO)\n",
    "# =============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Función de preprocesamiento tabular\n",
    "def preprocess_tabular(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Aplica imputación, escalado y codificación one-hot\n",
    "    de forma consistente en train y test.\n",
    "    \"\"\"\n",
    "    # Variables categóricas y numéricas\n",
    "    cat_features = [\"country\", \"region\", \"incomeLevel\"]\n",
    "    num_features = [col for col in X_train.columns if col not in cat_features]\n",
    "\n",
    "    # Transformadores\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", Pipeline([\n",
    "                (\"imputer\", IterativeImputer(max_iter=10, random_state=42)),\n",
    "                (\"scaler\", StandardScaler())\n",
    "            ]), num_features),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features)\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    return X_train_processed, X_test_processed, preprocessor\n",
    "\n",
    "\n",
    "# Features numéricas para LSTM\n",
    "features_lstm = df_featured.select_dtypes(include=np.number).columns.tolist()\n",
    "features_lstm = [col for col in features_lstm if col != TARGET]\n",
    "\n",
    "look_back = 3\n",
    "X_seq, y_seq, years_seq, countries_seq = create_lstm_sequences_global(\n",
    "    df_featured, features_lstm, TARGET, look_back\n",
    ")\n",
    "\n",
    "unique_years = df_featured['year'].unique()\n",
    "unique_years.sort()\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(unique_years)):\n",
    "    print(f\"\\n===== FOLD {fold+1}/{n_splits} =====\")\n",
    "\n",
    "    train_years = [unique_years[i] for i in train_idx]\n",
    "    test_years = [unique_years[i] for i in test_idx]\n",
    "\n",
    "    # === Random Forest / XGBoost ===\n",
    "    mask_train = df_featured['year'].isin(train_years)\n",
    "    mask_test = df_featured['year'].isin(test_years)\n",
    "\n",
    "    X_train_tab = X.loc[mask_train].copy()\n",
    "    y_train_tab = y.loc[mask_train]\n",
    "    X_test_tab = X.loc[mask_test].copy()\n",
    "    y_test_tab = y.loc[mask_test]\n",
    "\n",
    "    # Preprocesar\n",
    "    X_train_tab, X_test_tab, preprocessor = preprocess_tabular(X_train_tab, X_test_tab)\n",
    "\n",
    "    # Random Forest\n",
    "    y_true_rf, y_pred_rf = train_random_forest(X_train_tab, y_train_tab, X_test_tab, y_test_tab)\n",
    "    results['RandomForest'].append((y_true_rf, y_pred_rf))\n",
    "\n",
    "    # XGBoost\n",
    "    y_true_xgb, y_pred_xgb = train_xgboost(X_train_tab, y_train_tab, X_test_tab, y_test_tab)\n",
    "    results['XGBoost'].append((y_true_xgb, y_pred_xgb))\n",
    "\n",
    "\n",
    "    # === LSTM ===\n",
    "    mask_train_lstm = np.isin(years_seq, train_years)\n",
    "    mask_test_lstm = np.isin(years_seq, test_years)\n",
    "\n",
    "    X_train_lstm, y_train_lstm = X_seq[mask_train_lstm], y_seq[mask_train_lstm]\n",
    "    X_test_lstm, y_test_lstm = X_seq[mask_test_lstm], y_seq[mask_test_lstm]\n",
    "\n",
    "    y_true_lstm, y_pred_lstm = train_lstm(X_train_lstm, y_train_lstm, X_test_lstm, y_test_lstm, look_back)\n",
    "    if y_true_lstm is not None:\n",
    "        results['LSTM'].append((y_true_lstm, y_pred_lstm))\n",
    "    else:\n",
    "        results['LSTM'].append(([], []))\n",
    "\n",
    "\n",
    "    # === Prophet con regresores ===\n",
    "    try:\n",
    "        # Variables adicionales como regresores externos\n",
    "        regressors = [\"pib_per_capita\", \"gasto_educacion_gobierno\"]\n",
    "\n",
    "        y_true_prophet, y_pred_prophet = train_prophet(\n",
    "            df_featured, train_years, test_years, TARGET, regressors=regressors\n",
    "        )\n",
    "        results['Prophet'].append((y_true_prophet, y_pred_prophet))\n",
    "    except Exception as e:\n",
    "        results['Prophet'].append(([], []))\n",
    "        print(f\"⚠️ Prophet falló en fold {fold+1}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da6e159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Resultados finales ===\n",
      "\n",
      "Prophet:\n",
      "  MAE: 31094490.5729\n",
      "  RMSE: 70200229.4628\n",
      "  R2: -0.0283\n",
      "  MAPE: 63084.9990\n",
      "  SMAPE: 138.0917\n",
      "\n",
      "RandomForest:\n",
      "  MAE: 8637875.7723\n",
      "  RMSE: 36307239.4780\n",
      "  R2: 0.7189\n",
      "  MAPE: 340.0481\n",
      "  SMAPE: 47.8957\n",
      "\n",
      "XGBoost:\n",
      "  MAE: 6559937.1293\n",
      "  RMSE: 25350348.5323\n",
      "  R2: 0.7965\n",
      "  MAPE: 234.9338\n",
      "  SMAPE: 50.2811\n",
      "\n",
      "LSTM:\n",
      "  MAE: 6981599.9816\n",
      "  RMSE: 15296019.9750\n",
      "  R2: 0.9025\n",
      "  MAPE: 1859.9406\n",
      "  SMAPE: 71.0238\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 6. EVALUACIÓN DE MÉTRICAS (OPTIMIZADA)\n",
    "# =============================================================================\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    y_true = np.array(y_true, dtype=float)\n",
    "    y_pred = np.array(y_pred, dtype=float)\n",
    "\n",
    "    if len(y_true) == 0 or len(y_pred) == 0:\n",
    "        return None\n",
    "\n",
    "    # Filtrar valores NaN o inf\n",
    "    mask = ~np.isnan(y_true) & ~np.isnan(y_pred) & ~np.isinf(y_true) & ~np.isinf(y_pred)\n",
    "    y_true, y_pred = y_true[mask], y_pred[mask]\n",
    "\n",
    "    if len(y_true) == 0:\n",
    "        return None\n",
    "\n",
    "    # MAE, RMSE, R2\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    # MAPE más estable: ignorar ceros\n",
    "    non_zero_mask = y_true != 0\n",
    "    if non_zero_mask.any():\n",
    "        mape = np.mean(np.abs((y_true[non_zero_mask] - y_pred[non_zero_mask]) / y_true[non_zero_mask])) * 100\n",
    "    else:\n",
    "        mape = np.nan  # si todo es cero, no se calcula\n",
    "\n",
    "    # SMAPE alternativo\n",
    "    smape = np.mean(2.0 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-6)) * 100\n",
    "\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"MAPE\": mape, \"SMAPE\": smape}\n",
    "\n",
    "\n",
    "# Resumen de métricas\n",
    "summary = {}\n",
    "print(\"\\n=== Resultados finales ===\")\n",
    "for model, folds in results.items():\n",
    "    fold_metrics = []\n",
    "    for (y_true, y_pred) in folds:\n",
    "        m = compute_metrics(y_true, y_pred)\n",
    "        if m:\n",
    "            fold_metrics.append(m)\n",
    "    if fold_metrics:\n",
    "        avg_metrics = {k: np.nanmean([fm[k] for fm in fold_metrics]) for k in fold_metrics[0]}\n",
    "        summary[model] = avg_metrics\n",
    "        print(f\"\\n{model}:\")\n",
    "        for k, v in avg_metrics.items():\n",
    "            print(f\"  {k}: {v:.4f}\")\n",
    "    else:\n",
    "        print(f\"\\n{model}: sin resultados\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67b67ad",
   "metadata": {},
   "source": [
    "# PRUEBA con optimización de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "535741f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. OPTIMIZACIÓN DE MODELOS\n",
    "# =============================================================================\n",
    "\n",
    "def optimize_random_forest(X_train, y_train):\n",
    "    param_dist = {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [None, 10, 20],\n",
    "        \"min_samples_leaf\": [1, 2, 5],\n",
    "    }\n",
    "    rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "    search = RandomizedSearchCV(rf, param_distributions=param_dist,\n",
    "                                n_iter=5, scoring=\"neg_mean_absolute_error\",\n",
    "                                cv=3, random_state=42)\n",
    "    search.fit(X_train, y_train)\n",
    "    return search.best_estimator_\n",
    "\n",
    "def optimize_xgboost(X_train, y_train):\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [100, 200, 500],\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"subsample\": [0.7, 0.9, 1.0],\n",
    "    }\n",
    "\n",
    "    best_model, best_mae = None, float(\"inf\")\n",
    "\n",
    "    for n in param_grid[\"n_estimators\"]:\n",
    "        for d in param_grid[\"max_depth\"]:\n",
    "            for lr in param_grid[\"learning_rate\"]:\n",
    "                for subs in param_grid[\"subsample\"]:\n",
    "                    model = xgb.XGBRegressor(\n",
    "                        n_estimators=n,\n",
    "                        max_depth=d,\n",
    "                        learning_rate=lr,\n",
    "                        subsample=subs,\n",
    "                        random_state=42,\n",
    "                        n_jobs=-1\n",
    "                    )\n",
    "                    model.fit(X_train, y_train)\n",
    "                    preds = model.predict(X_train)\n",
    "                    mae = mean_absolute_error(y_train, preds)\n",
    "                    if mae < best_mae:\n",
    "                        best_mae = mae\n",
    "                        best_model = model\n",
    "    return best_model\n",
    "\n",
    "def optimize_lstm(X_train, y_train, look_back):\n",
    "    param_grid = [\n",
    "        {\"units\": 50, \"dropout\": 0.2, \"epochs\": 10, \"batch_size\": 16},\n",
    "        {\"units\": 100, \"dropout\": 0.3, \"epochs\": 20, \"batch_size\": 32},\n",
    "    ]\n",
    "\n",
    "    best_model, best_mae = None, float(\"inf\")\n",
    "\n",
    "    for params in param_grid:\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.LSTM(params[\"units\"], activation=\"relu\",\n",
    "                                 input_shape=(look_back, X_train.shape[2])),\n",
    "            tf.keras.layers.Dropout(params[\"dropout\"]),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer=\"adam\", loss=\"mae\")\n",
    "        model.fit(X_train, y_train,\n",
    "                  epochs=params[\"epochs\"],\n",
    "                  batch_size=params[\"batch_size\"],\n",
    "                  verbose=0)\n",
    "\n",
    "        preds = model.predict(X_train, verbose=0).flatten()\n",
    "        mae = mean_absolute_error(y_train, preds)\n",
    "\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_model = model\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def optimize_prophet(train_df, target):\n",
    "    param_grid = [\n",
    "        {\"changepoint_prior_scale\": 0.01, \"seasonality_prior_scale\": 5},\n",
    "        {\"changepoint_prior_scale\": 0.1, \"seasonality_prior_scale\": 10},\n",
    "        {\"changepoint_prior_scale\": 0.5, \"seasonality_prior_scale\": 15},\n",
    "    ]\n",
    "\n",
    "    best_model, best_mae = None, float(\"inf\")\n",
    "\n",
    "    for params in param_grid:\n",
    "        m = Prophet(\n",
    "            yearly_seasonality=True,\n",
    "            daily_seasonality=False,\n",
    "            changepoint_prior_scale=params[\"changepoint_prior_scale\"],\n",
    "            seasonality_prior_scale=params[\"seasonality_prior_scale\"]\n",
    "        )\n",
    "        prophet_train = train_df.rename(columns={\"year\": \"ds\", target: \"y\"})\n",
    "        m.fit(prophet_train)\n",
    "        forecast = m.predict(prophet_train[[\"ds\"]])\n",
    "        mae = mean_absolute_error(prophet_train[\"y\"], forecast[\"yhat\"])\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_model = m\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f650a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BLOQUE MÉTRICAS\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"Symmetric Mean Absolute Percentage Error\"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return 100/len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / \n",
    "                                    (np.abs(y_true) + np.abs(y_pred) + 1e-6))\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    if len(y_true) == 0 or len(y_pred) == 0:\n",
    "        return None\n",
    "    return {\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"SMAPE\": smape(y_true, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b55cc261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. EJECUCIÓN DE MODELOS (USA OPTIMIZACIÓN)\n",
    "# =============================================================================\n",
    "\n",
    "def run_random_forest(X_train, y_train, X_test, y_test):\n",
    "    model = optimize_random_forest(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_test, y_pred, model.get_params()\n",
    "\n",
    "def run_xgboost(X_train, y_train, X_test, y_test):\n",
    "    model = optimize_xgboost(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_test, y_pred, model.get_params()\n",
    "\n",
    "def run_lstm(X_train, y_train, X_test, y_test, look_back):\n",
    "    param_grid = [\n",
    "        {\"units\": 50, \"dropout\": 0.2, \"epochs\": 10, \"batch_size\": 16},\n",
    "        {\"units\": 100, \"dropout\": 0.3, \"epochs\": 20, \"batch_size\": 32},\n",
    "    ]\n",
    "\n",
    "    best_model, best_mae, best_params = None, float(\"inf\"), None\n",
    "\n",
    "    for params in param_grid:\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.LSTM(params[\"units\"], activation=\"relu\",\n",
    "                                 input_shape=(look_back, X_train.shape[2])),\n",
    "            tf.keras.layers.Dropout(params[\"dropout\"]),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer=\"adam\", loss=\"mae\")\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=params[\"epochs\"],\n",
    "            batch_size=params[\"batch_size\"],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        preds = model.predict(X_train, verbose=0).flatten()\n",
    "        mae = mean_absolute_error(y_train, preds)\n",
    "\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_model = model\n",
    "            best_params = params  # 🔹 Guardamos directamente los parámetros probados\n",
    "\n",
    "    if best_model is None:\n",
    "        return [], [], {}\n",
    "\n",
    "    # Predicciones finales con el mejor modelo\n",
    "    y_pred = best_model.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "    return y_test, y_pred, best_params  # 🔹 Retornamos params directamente\n",
    "\n",
    "\n",
    "def run_prophet(train_df, test_df, target, regressors=None):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa Prophet en un fold.\n",
    "    - train_df y test_df: subconjuntos de datos (DataFrames).\n",
    "    - target: variable objetivo.\n",
    "    - regressors: lista opcional de regresores externos.\n",
    "    \"\"\"\n",
    "    # Preparar datasets\n",
    "    prophet_train = train_df[['year', target]].rename(columns={'year': 'ds', target: 'y'})\n",
    "    prophet_test = test_df[['year', target]].rename(columns={'year': 'ds', target: 'y'})\n",
    "\n",
    "    # Convertir a datetime para Prophet\n",
    "    prophet_train['ds'] = pd.to_datetime(prophet_train['ds'], format='%Y')\n",
    "    prophet_test['ds'] = pd.to_datetime(prophet_test['ds'], format='%Y')\n",
    "\n",
    "    # Inicializar Prophet\n",
    "    m = Prophet(\n",
    "        yearly_seasonality=True,\n",
    "        daily_seasonality=False,\n",
    "        changepoint_prior_scale=0.1,\n",
    "        seasonality_prior_scale=10\n",
    "    )\n",
    "\n",
    "    # Agregar regresores si existen\n",
    "    if regressors:\n",
    "        for reg in regressors:\n",
    "            if reg in train_df.columns:\n",
    "                m.add_regressor(reg)\n",
    "\n",
    "    # Ajustar el modelo\n",
    "    train_with_regs = prophet_train.copy()\n",
    "    if regressors:\n",
    "        for reg in regressors:\n",
    "            train_with_regs[reg] = train_df[reg].values\n",
    "\n",
    "    m.fit(train_with_regs)\n",
    "\n",
    "    # Preparar datos futuros\n",
    "    future = prophet_test[['ds']].copy()\n",
    "    if regressors:\n",
    "        for reg in regressors:\n",
    "            future[reg] = test_df[reg].values\n",
    "\n",
    "    forecast = m.predict(future)\n",
    "\n",
    "    return prophet_test['y'].values, forecast['yhat'].values, {\n",
    "        \"changepoint_prior_scale\": m.changepoint_prior_scale,\n",
    "        \"seasonality_prior_scale\": m.seasonality_prior_scale,\n",
    "        \"regressors\": regressors if regressors else []\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4885f3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 1/5 =====\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 15:13:15.595891: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-12 15:13:15.758547: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-12 15:13:20.554036: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 15:13:21.514152: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-12 15:13:21.681781: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-12 15:13:26.090486: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 2/5 =====\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 15:13:47.367068: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-12 15:13:47.558714: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-12 15:13:54.112326: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 15:13:55.074448: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-12 15:13:55.261764: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-12 15:14:01.902767: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 3/5 =====\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 15:14:23.683814: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-12 15:14:23.865095: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-12 15:14:31.936144: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 15:14:32.915556: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-12 15:14:33.099831: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-12 15:14:41.110533: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 4/5 =====\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 15:15:04.224427: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-12 15:15:04.398472: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-12 15:15:14.843554: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 15:15:15.834703: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-12 15:15:16.011354: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-12 15:15:26.207150: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 5/5 =====\n",
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 15:15:47.308662: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-12 15:15:47.461187: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-12 15:15:59.653423: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 15:16:00.702911: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-12 15:16:00.857215: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-12 15:16:13.150570: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "15:16:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:16:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 6. LOOP DE CROSS-VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "results_detailed = { \"Prophet\": [], \"RandomForest\": [], \"XGBoost\": [], \"LSTM\": [] }\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(unique_years)):\n",
    "    print(f\"\\n===== FOLD {fold+1}/{n_splits} =====\")\n",
    "    train_years = [unique_years[i] for i in train_idx]\n",
    "    test_years = [unique_years[i] for i in test_idx]\n",
    "\n",
    "    # === Datos tabulares ===\n",
    "    mask_train = df_featured['year'].isin(train_years)\n",
    "    mask_test = df_featured['year'].isin(test_years)\n",
    "    X_train_tab = X.loc[mask_train].select_dtypes(include=np.number)\n",
    "    y_train_tab = y.loc[mask_train]\n",
    "    X_test_tab = X.loc[mask_test].select_dtypes(include=np.number)\n",
    "    y_test_tab = y.loc[mask_test]\n",
    "\n",
    "    # Preprocesamiento\n",
    "    imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_tab = scaler.fit_transform(imputer.fit_transform(X_train_tab))\n",
    "    X_test_tab = scaler.transform(imputer.transform(X_test_tab))\n",
    "\n",
    "    # --- Random Forest ---\n",
    "    y_true_rf, y_pred_rf, params_rf = run_random_forest(X_train_tab, y_train_tab, X_test_tab, y_test_tab)\n",
    "    metrics_rf = compute_metrics(y_true_rf, y_pred_rf)\n",
    "    results_detailed[\"RandomForest\"].append({**metrics_rf, \"params\": params_rf, \"fold\": fold+1})\n",
    "\n",
    "    # --- XGBoost ---\n",
    "    y_true_xgb, y_pred_xgb, params_xgb = run_xgboost(X_train_tab, y_train_tab, X_test_tab, y_test_tab)\n",
    "    metrics_xgb = compute_metrics(y_true_xgb, y_pred_xgb)\n",
    "    results_detailed[\"XGBoost\"].append({**metrics_xgb, \"params\": params_xgb, \"fold\": fold+1})\n",
    "\n",
    "    # --- LSTM ---\n",
    "    mask_train_lstm = np.isin(years_seq, train_years)\n",
    "    mask_test_lstm = np.isin(years_seq, test_years)\n",
    "    X_train_lstm, y_train_lstm = X_seq[mask_train_lstm], y_seq[mask_train_lstm]\n",
    "    X_test_lstm, y_test_lstm = X_seq[mask_test_lstm], y_seq[mask_test_lstm]\n",
    "    y_true_lstm, y_pred_lstm, params_lstm = run_lstm(X_train_lstm, y_train_lstm, X_test_lstm, y_test_lstm, look_back)\n",
    "    if len(y_true_lstm) > 0:\n",
    "        metrics_lstm = compute_metrics(y_true_lstm, y_pred_lstm)\n",
    "        results_detailed[\"LSTM\"].append({**metrics_lstm, \"params\": params_lstm, \"fold\": fold+1})\n",
    "\n",
    "    # Definir regresores opcionales (ejemplo: variables socioeconómicas)\n",
    "prophet_regressors = [\"pib_per_capita\", \"gasto_educacion_gobierno\", \"PCA1\", \"PCA2\", \"superficie_total_km2\",  \"gasto_educacion_pib\", \"gasto_educacion_gobierno\"]\n",
    "\n",
    "# Prophet\n",
    "try:\n",
    "    prophet_train = df_featured[df_featured[\"year\"].isin(train_years)]\n",
    "    prophet_test = df_featured[df_featured[\"year\"].isin(test_years)]\n",
    "    y_true_prophet, y_pred_prophet, params_prophet = run_prophet(\n",
    "        prophet_train, prophet_test, TARGET, regressors=prophet_regressors\n",
    "    )\n",
    "    metrics_prophet = compute_metrics(y_true_prophet, y_pred_prophet)\n",
    "    results_detailed[\"Prophet\"].append({**metrics_prophet, \"params\": params_prophet, \"fold\": fold+1})\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Prophet falló en fold {fold+1}: {e}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a3dc41e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Resultados Detallados ===\n",
      "           model  fold           MAE          RMSE        R2       SMAPE  \\\n",
      "0        Prophet     5  5.593730e+07  1.279492e+08 -0.022634  129.957022   \n",
      "1   RandomForest     1  4.371994e+06  1.812670e+07  0.622490   78.203109   \n",
      "2   RandomForest     2  6.735821e+06  2.653531e+07  0.691307   66.670576   \n",
      "3   RandomForest     3  6.285663e+06  1.826668e+07  0.894061   45.563590   \n",
      "4   RandomForest     4  1.327231e+07  5.075060e+07  0.652979   27.537785   \n",
      "5   RandomForest     5  1.907566e+07  7.744264e+07  0.625368   26.131990   \n",
      "6        XGBoost     1  4.234149e+06  1.693988e+07  0.670306   87.087511   \n",
      "7        XGBoost     2  5.008329e+06  1.688554e+07  0.875001   75.490959   \n",
      "8        XGBoost     3  4.311654e+06  9.564915e+06  0.970953   63.742064   \n",
      "9        XGBoost     4  9.817560e+06  3.704550e+07  0.815097   48.023371   \n",
      "10       XGBoost     5  9.058047e+06  3.694684e+07  0.914729   33.983425   \n",
      "11          LSTM     1  3.442083e+06  9.463904e+06  0.897096   95.897051   \n",
      "12          LSTM     2  3.904168e+06  9.344643e+06  0.961717   72.848297   \n",
      "13          LSTM     3  4.840156e+06  1.048118e+07  0.965122   65.594194   \n",
      "14          LSTM     4  4.143091e+06  7.955950e+06  0.991472   40.510671   \n",
      "15          LSTM     5  7.242240e+06  1.906395e+07  0.977298   33.253128   \n",
      "\n",
      "                                               params  \n",
      "0   {'changepoint_prior_scale': 0.1, 'seasonality_...  \n",
      "1   {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...  \n",
      "2   {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...  \n",
      "3   {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...  \n",
      "4   {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...  \n",
      "5   {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...  \n",
      "6   {'objective': 'reg:squarederror', 'base_score'...  \n",
      "7   {'objective': 'reg:squarederror', 'base_score'...  \n",
      "8   {'objective': 'reg:squarederror', 'base_score'...  \n",
      "9   {'objective': 'reg:squarederror', 'base_score'...  \n",
      "10  {'objective': 'reg:squarederror', 'base_score'...  \n",
      "11  {'units': 100, 'dropout': 0.3, 'epochs': 20, '...  \n",
      "12  {'units': 100, 'dropout': 0.3, 'epochs': 20, '...  \n",
      "13  {'units': 100, 'dropout': 0.3, 'epochs': 20, '...  \n",
      "14  {'units': 100, 'dropout': 0.3, 'epochs': 20, '...  \n",
      "15  {'units': 100, 'dropout': 0.3, 'epochs': 20, '...  \n",
      "\n",
      "=== Promedio por modelo ===\n",
      "                       MAE          RMSE        R2       SMAPE\n",
      "model                                                         \n",
      "LSTM          4.714348e+06  1.126193e+07  0.958541   61.620668\n",
      "Prophet       5.593730e+07  1.279492e+08 -0.022634  129.957022\n",
      "RandomForest  9.948289e+06  3.822439e+07  0.697241   48.821410\n",
      "XGBoost       6.485948e+06  2.347653e+07  0.849217   61.665466\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 7. EVALUACIÓN DE MÉTRICAS\n",
    "# =============================================================================\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# =============================================================================\n",
    "# BLOQUE DE RESUMEN FINAL\n",
    "# =============================================================================\n",
    "all_results = []\n",
    "for model, folds in results_detailed.items():\n",
    "    for res in folds:\n",
    "        res[\"model\"] = model\n",
    "        all_results.append(res)\n",
    "\n",
    "df_results = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"\\n=== Resultados Detallados ===\")\n",
    "print(df_results[[\"model\", \"fold\", \"MAE\", \"RMSE\", \"R2\", \"SMAPE\", \"params\"]])\n",
    "\n",
    "print(\"\\n=== Promedio por modelo ===\")\n",
    "print(df_results.groupby(\"model\")[[\"MAE\", \"RMSE\", \"R2\", \"SMAPE\"]].mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
