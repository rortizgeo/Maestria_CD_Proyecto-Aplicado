{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75e564d",
   "metadata": {},
   "source": [
    "\n",
    "# Objetivo 2: Generación de modelos\n",
    "\n",
    "Pipeline completo para la predicción del crecimiento de datos de biodiversidad en GBIF.\n",
    "\n",
    "Este script implementa el flujo de trabajo de principio a fin para modelar datos de panel\n",
    "de series temporales, incluyendo:\n",
    "1.  Carga datos de PA_dataAnalysis y preparación\n",
    "2.  Ingeniería de características temporales (lags y ventanas móviles).\n",
    "3.  Un marco de validación cruzada robusto para series de tiempo (ventana expansiva).\n",
    "4.  Preprocesamiento (imputación y escalado) dentro del bucle de validación para evitar fuga de datos.\n",
    "5.  Entrenamiento y evaluación comparativa de cuatro modelos:\n",
    "    - Prophet.\n",
    "    - Random Forest.\n",
    "    - XGBoost.\n",
    "    - Red Neuronal LSTM (para modelado secuencial).\n",
    "6.  Selección del mejor modelo basado en métricas de rendimiento (MAE, RMSE, R²).\n",
    "7.  Reentrenamiento del modelo final y generación de pronósticos para Colombia hasta 2030\n",
    "    bajo dos escenarios de políticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8d92da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. IMPORTACIÓN DE LIBRERÍAS Y CONFIGURACIÓN INICIAL\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Preprocesamiento y modelado de Scikit-Learn\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Modelos especializados\n",
    "\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from prophet import Prophet\n",
    "\n",
    "# Configuraciones generales\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7bec6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelado de Deep Learning con TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24978f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga de datos\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/rortizgeo/Maestria_CD_Proyecto-Aplicado/main/Data_final.csv\"\n",
    "Data_final = pd.read_csv(url)\n",
    "\n",
    "# Eliminación de columnas por tener muchos vacíos y no ser posible completarlas con imputación. (pensar en otras estrategias)\n",
    "columns_to_drop = ['Overall score', 'areas_protegidas']\n",
    "Data_final = Data_final.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126e13f3",
   "metadata": {},
   "source": [
    "Para aplicar modelos como Random Forest y XGBoost, es necesario agregar características de temporalidad en los datos, para lo cuál es necesario calcular retardos, que se deben aplicar teniendo en cuenta un análisis del ACF Y PACF, así como la incorporación de los tiempos del retardo como hiperparámetros. \n",
    "\n",
    "Los modelos basados en árboles como Random Forest y XGBoost no son conscientes de la secuencia temporal de los datos y no pueden \"extrapolar\" tendencias más allá de los valores que han visto en el entrenamiento. Por lo tanto, es necesario convertir la información temporal en características que el modelo pueda entender. La creación de retardos (lags) y estadísticas de ventana móvil es la técnica estándar para lograrlo. Se podría identificar el número de retardos como un hiperparámetro, guiado por análisis de ACF y PACF (Ver EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0cadacbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Paso 2: Realizando ingeniería de características temporales...\n",
      "Ingeniería de características completada.\n",
      "Shape del dataset: (656, 58)\n",
      "Valores NaN restantes: 0\n",
      "\n",
      "Estadísticas de las nuevas características:\n",
      "       occurrenceCount_publisher_lag1  occurrenceCount_publisher_lag2  \\\n",
      "count                    6.560000e+02                    6.560000e+02   \n",
      "mean                     1.530224e+07                    1.257584e+07   \n",
      "std                      5.295431e+07                    4.383457e+07   \n",
      "min                      0.000000e+00                    0.000000e+00   \n",
      "25%                      1.549475e+04                    1.335000e+02   \n",
      "50%                      1.176419e+06                    5.515200e+05   \n",
      "75%                      9.340858e+06                    7.115654e+06   \n",
      "max                      7.401771e+08                    5.946568e+08   \n",
      "\n",
      "       occurrenceCount_publisher_lag3  occurrenceCount_publisher_lag4  \\\n",
      "count                    6.560000e+02                    6.560000e+02   \n",
      "mean                     1.024584e+07                    8.296004e+06   \n",
      "std                      3.656712e+07                    3.057768e+07   \n",
      "min                      0.000000e+00                    0.000000e+00   \n",
      "25%                      0.000000e+00                    0.000000e+00   \n",
      "50%                      2.662950e+05                    1.096710e+05   \n",
      "75%                      5.047951e+06                    3.175013e+06   \n",
      "max                      4.897051e+08                    3.528648e+08   \n",
      "\n",
      "       occurrenceCount_publisher_lag5  occurrenceCount_publisher_rollmean3  \\\n",
      "count                    6.560000e+02                         6.560000e+02   \n",
      "mean                     6.738803e+06                         1.668685e+07   \n",
      "std                      2.673301e+07                         5.368850e+07   \n",
      "min                      0.000000e+00                         0.000000e+00   \n",
      "25%                      0.000000e+00                         7.333842e+04   \n",
      "50%                      1.874800e+04                         1.624914e+06   \n",
      "75%                      2.448169e+06                         1.190595e+07   \n",
      "max                      3.442562e+08                         6.674169e+08   \n",
      "\n",
      "       occurrenceCount_publisher_rollstd3  \\\n",
      "count                        6.560000e+02   \n",
      "mean                         4.812063e+06   \n",
      "std                          2.360976e+07   \n",
      "min                          0.000000e+00   \n",
      "25%                          8.972601e+03   \n",
      "50%                          3.353990e+05   \n",
      "75%                          2.509022e+06   \n",
      "max                          5.233843e+08   \n",
      "\n",
      "       occurrenceCount_publisher_rollmean5  \\\n",
      "count                         6.560000e+02   \n",
      "mean                          1.657737e+07   \n",
      "std                           4.957963e+07   \n",
      "min                           0.000000e+00   \n",
      "25%                           1.419378e+05   \n",
      "50%                           2.011318e+06   \n",
      "75%                           1.261729e+07   \n",
      "max                           5.443510e+08   \n",
      "\n",
      "       occurrenceCount_publisher_rollstd5  \\\n",
      "count                        6.560000e+02   \n",
      "mean                         7.874283e+06   \n",
      "std                          2.826472e+07   \n",
      "min                          0.000000e+00   \n",
      "25%                          4.817769e+04   \n",
      "50%                          1.016754e+06   \n",
      "75%                          6.251451e+06   \n",
      "max                          3.898861e+08   \n",
      "\n",
      "       occurrenceCount_publisher_rollmean7  ...  gasto_educacion_pib_lag2  \\\n",
      "count                         6.560000e+02  ...                656.000000   \n",
      "mean                          1.649014e+07  ...                  4.266209   \n",
      "std                           4.648245e+07  ...                  2.122214   \n",
      "min                           0.000000e+00  ...                  0.000000   \n",
      "25%                           2.050516e+05  ...                  3.148687   \n",
      "50%                           2.304801e+06  ...                  4.781910   \n",
      "75%                           1.425623e+07  ...                  5.510889   \n",
      "max                           4.764592e+08  ...                  8.583830   \n",
      "\n",
      "       gasto_educacion_pib_lag3  gasto_educacion_pib_lag4  \\\n",
      "count                656.000000                656.000000   \n",
      "mean                   3.949542                  3.644751   \n",
      "std                    2.314343                  2.458819   \n",
      "min                    0.000000                  0.000000   \n",
      "25%                    2.549517                  0.830940   \n",
      "50%                    4.632265                  4.480175   \n",
      "75%                    5.462904                  5.431867   \n",
      "max                    8.559550                  8.559550   \n",
      "\n",
      "       gasto_educacion_pib_lag5  gasto_educacion_pib_rollmean3  \\\n",
      "count                656.000000                     656.000000   \n",
      "mean                   3.342840                       4.855040   \n",
      "std                    2.563963                       1.447663   \n",
      "min                    0.000000                       0.000000   \n",
      "25%                    0.000000                       4.100878   \n",
      "50%                    4.224074                       4.932528   \n",
      "75%                    5.389558                       5.550119   \n",
      "max                    8.559550                       8.497764   \n",
      "\n",
      "       gasto_educacion_pib_rollstd3  gasto_educacion_pib_rollmean5  \\\n",
      "count                    656.000000                     656.000000   \n",
      "mean                       0.277200                       4.856486   \n",
      "std                        0.361797                       1.407998   \n",
      "min                        0.000000                       0.000000   \n",
      "25%                        0.088735                       4.122125   \n",
      "50%                        0.175620                       4.932367   \n",
      "75%                        0.331003                       5.533535   \n",
      "max                        3.467356                       8.245108   \n",
      "\n",
      "       gasto_educacion_pib_rollstd5  gasto_educacion_pib_rollmean7  \\\n",
      "count                    656.000000                     656.000000   \n",
      "mean                       0.391173                       4.856149   \n",
      "std                        0.402508                       1.373718   \n",
      "min                        0.000000                       0.000000   \n",
      "25%                        0.153728                       4.130995   \n",
      "50%                        0.278714                       4.933646   \n",
      "75%                        0.480313                       5.545625   \n",
      "max                        2.898983                       8.048063   \n",
      "\n",
      "       gasto_educacion_pib_rollstd7  \n",
      "count                    656.000000  \n",
      "mean                       0.476935  \n",
      "std                        0.425371  \n",
      "min                        0.000000  \n",
      "25%                        0.228329  \n",
      "50%                        0.358580  \n",
      "75%                        0.563539  \n",
      "max                        2.716642  \n",
      "\n",
      "[8 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2. INGENIERÍA DE CARACTERÍSTICAS TEMPORALES (OPTIMIZADA)\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nPaso 2: Realizando ingeniería de características temporales...\")\n",
    "\n",
    "TARGET = 'occurrenceCount_publisher'\n",
    "\n",
    "def create_temporal_features_optimized(data, features_to_lag, \n",
    "                                     lags=[1, 2, 3, 4, 5], \n",
    "                                     roll_windows=[3, 5, 7],\n",
    "                                     fill_na=0):\n",
    "    \"\"\"\n",
    "    Genera características temporales y completa automáticamente con 0\n",
    "    los valores NaN generados, según la lógica del negocio.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Dataset con al menos 'country' y variables numéricas.\n",
    "    features_to_lag : list\n",
    "        Lista de columnas numéricas a transformar.\n",
    "    lags : list\n",
    "        Lista de retardos.\n",
    "    roll_windows : list\n",
    "        Lista de ventanas móviles.\n",
    "    fill_na : int/float\n",
    "        Valor para completar NaN (0 por defecto según lógica de negocio).\n",
    "        \n",
    "    Retorna\n",
    "    -------\n",
    "    DataFrame con nuevas características y NaN completados.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_copy = data.copy()\n",
    "    \n",
    "    for feature in features_to_lag:\n",
    "        # Características de lag\n",
    "        for lag in lags:\n",
    "            lag_col = f'{feature}_lag{lag}'\n",
    "            df_copy[lag_col] = df_copy.groupby('country')[feature].shift(lag)\n",
    "            df_copy[lag_col] = df_copy[lag_col].fillna(fill_na)\n",
    "        \n",
    "        # Características de ventana móvil\n",
    "        for w in roll_windows:\n",
    "            # Rolling mean\n",
    "            mean_col = f'{feature}_rollmean{w}'\n",
    "            df_copy[mean_col] = (\n",
    "                df_copy.groupby('country')[feature]\n",
    "                .shift(1)\n",
    "                .rolling(window=w, min_periods=1)\n",
    "                .mean()\n",
    "            )\n",
    "            df_copy[mean_col] = df_copy[mean_col].fillna(fill_na)\n",
    "            \n",
    "            # Rolling std\n",
    "            std_col = f'{feature}_rollstd{w}'\n",
    "            df_copy[std_col] = (\n",
    "                df_copy.groupby('country')[feature]\n",
    "                .shift(1)\n",
    "                .rolling(window=w, min_periods=1)\n",
    "                .std()\n",
    "            )\n",
    "            df_copy[std_col] = df_copy[std_col].fillna(fill_na)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "# ===========================\n",
    "# Uso del código optimizado\n",
    "# ===========================\n",
    "features_to_lag = [\n",
    "    \"occurrenceCount_publisher\", \"pib_per_capita\",\n",
    "    \"gasto_educacion_gobierno\", \"gasto_educacion_pib\"\n",
    "]\n",
    "\n",
    "# Crear dataset con nuevas features (completando con 0)\n",
    "df_featured = create_temporal_features_optimized(\n",
    "    Data_final,\n",
    "    features_to_lag=features_to_lag,\n",
    "    lags=[1, 2, 3, 4, 5],  # Reducido para evitar overfitting\n",
    "    roll_windows=[3, 5, 7],  # Reducido para evitar overfitting\n",
    "    fill_na=0  # ¡IMPORTANTE! Completar con 0 según lógica de negocio\n",
    ")\n",
    "\n",
    "print(\"Ingeniería de características completada.\")\n",
    "print(f\"Shape del dataset: {df_featured.shape}\")\n",
    "print(f\"Valores NaN restantes: {df_featured.isnull().sum().sum()}\")\n",
    "\n",
    "# Mostrar estadísticas de las nuevas características\n",
    "print(\"\\nEstadísticas de las nuevas características:\")\n",
    "new_features = [col for col in df_featured.columns if any(x in col for x in ['_lag', '_roll'])]\n",
    "print(df_featured[new_features].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ed0b8e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de valores en características temporales:\n",
      "occurrenceCount_publisher_lag1: 18.8% ceros\n",
      "occurrenceCount_publisher_lag2: 25.0% ceros\n",
      "occurrenceCount_publisher_lag3: 31.2% ceros\n",
      "occurrenceCount_publisher_lag4: 37.5% ceros\n",
      "occurrenceCount_publisher_lag5: 43.8% ceros\n",
      "occurrenceCount_publisher_rollmean3: 9.9% ceros\n",
      "occurrenceCount_publisher_rollstd3: 15.4% ceros\n",
      "occurrenceCount_publisher_rollmean5: 5.9% ceros\n",
      "occurrenceCount_publisher_rollstd5: 7.6% ceros\n",
      "occurrenceCount_publisher_rollmean7: 3.7% ceros\n",
      "occurrenceCount_publisher_rollstd7: 4.3% ceros\n",
      "pib_per_capita_lag1: 6.2% ceros\n",
      "pib_per_capita_lag2: 12.5% ceros\n",
      "pib_per_capita_lag3: 18.8% ceros\n",
      "pib_per_capita_lag4: 25.0% ceros\n",
      "pib_per_capita_lag5: 31.2% ceros\n",
      "pib_per_capita_rollmean3: 0.2% ceros\n",
      "pib_per_capita_rollstd3: 0.3% ceros\n",
      "pib_per_capita_rollmean5: 0.2% ceros\n",
      "pib_per_capita_rollstd5: 0.3% ceros\n",
      "pib_per_capita_rollmean7: 0.2% ceros\n",
      "pib_per_capita_rollstd7: 0.3% ceros\n",
      "gasto_educacion_gobierno_lag1: 6.2% ceros\n",
      "gasto_educacion_gobierno_lag2: 12.5% ceros\n",
      "gasto_educacion_gobierno_lag3: 18.8% ceros\n",
      "gasto_educacion_gobierno_lag4: 25.0% ceros\n",
      "gasto_educacion_gobierno_lag5: 31.2% ceros\n",
      "gasto_educacion_gobierno_rollmean3: 0.2% ceros\n",
      "gasto_educacion_gobierno_rollstd3: 0.3% ceros\n",
      "gasto_educacion_gobierno_rollmean5: 0.2% ceros\n",
      "gasto_educacion_gobierno_rollstd5: 0.3% ceros\n",
      "gasto_educacion_gobierno_rollmean7: 0.2% ceros\n",
      "gasto_educacion_gobierno_rollstd7: 0.3% ceros\n",
      "gasto_educacion_pib_lag1: 6.2% ceros\n",
      "gasto_educacion_pib_lag2: 12.5% ceros\n",
      "gasto_educacion_pib_lag3: 18.8% ceros\n",
      "gasto_educacion_pib_lag4: 25.0% ceros\n",
      "gasto_educacion_pib_lag5: 31.2% ceros\n",
      "gasto_educacion_pib_rollmean3: 0.2% ceros\n",
      "gasto_educacion_pib_rollstd3: 0.3% ceros\n",
      "gasto_educacion_pib_rollmean5: 0.2% ceros\n",
      "gasto_educacion_pib_rollstd5: 0.3% ceros\n",
      "gasto_educacion_pib_rollmean7: 0.2% ceros\n",
      "gasto_educacion_pib_rollstd7: 0.3% ceros\n"
     ]
    }
   ],
   "source": [
    "# Validar que no quedan NaN\n",
    "assert df_featured.isnull().sum().sum() == 0, \"¡Aún hay valores NaN!\"\n",
    "\n",
    "# Verificar distribución de las nuevas features\n",
    "print(\"Distribución de valores en características temporales:\")\n",
    "for col in new_features:\n",
    "    zero_percentage = (df_featured[col] == 0).mean() * 100\n",
    "    print(f\"{col}: {zero_percentage:.1f}% ceros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1dfbcc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Paso 3: Preparando el marco de validación y los datos para el modelado...\n",
      "Features seleccionadas: ['PC1', 'PC2', 'pib_per_capita', 'gasto_educacion_gobierno', 'gasto_educacion_pib', 'superficie_total_km2', 'country', 'region', 'occurrenceCount_publisher_lag2', 'occurrenceCount_publisher_rollmean3', 'occurrenceCount_publisher_rollstd3']\n",
      "X shape: (656, 11)\n",
      "y shape: (656,)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3. PREPARACIÓN PARA EL MODELADO Y VALIDACIÓN\n",
    "# =============================================================================\n",
    "print(\"\\nPaso 3: Preparando el marco de validación y los datos para el modelado...\")\n",
    "\n",
    "# Definir variable objetivo\n",
    "TARGET = 'occurrenceCount_publisher'\n",
    "\n",
    "# Definir variables predictoras (Decidir con Daniel cuáles usar basándose en EDA y disponibilidad. Preguntar si es posible usar todas sin complejizar el modelo)\n",
    "features = [\n",
    "    'PC1', 'PC2', 'pib_per_capita', 'gasto_educacion_gobierno',\n",
    "    'gasto_educacion_pib', 'superficie_total_km2', \"country\", \"region\", \"incomeLevel\"\n",
    "    f\"{TARGET}_lag1\", f\"{TARGET}_lag2\", f\"{TARGET}_rollmean3\", f\"{TARGET}_rollstd3\"\n",
    "]\n",
    "\n",
    "# Filtrar las variables que realmente existen en el DataFrame\n",
    "features = [f for f in features if f in df_featured.columns]\n",
    "\n",
    "# Definir X (predictoras) e y (objetivo)\n",
    "X = df_featured[features].copy()\n",
    "y = df_featured[TARGET].copy()\n",
    "\n",
    "# Configurar validación cruzada para series de tiempo\n",
    "n_splits = 5  # número de pliegues\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "# Diccionario para almacenar resultados\n",
    "results = {\n",
    "    'Prophet': None,\n",
    "    'RandomForest': None,\n",
    "    'XGBoost': None,\n",
    "    'LSTM': None\n",
    "}\n",
    "\n",
    "print(\"Features seleccionadas:\", features)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a2e95c",
   "metadata": {},
   "source": [
    "Pruebas de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "82955089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# A. CREACIÓN DE SECUENCIAS Y FUNCIONES DE MODELOS\n",
    "# =============================================================================\n",
    "\n",
    "def create_lstm_sequences_global(df, features, target, look_back=3):\n",
    "    \"\"\"\n",
    "    Crea secuencias LSTM para todos los países antes del split train/test.\n",
    "    Retorna X_seq, y_seq, years, countries (alineados).\n",
    "    \"\"\"\n",
    "    X_seq, y_seq, years, countries = [], [], [], []\n",
    "\n",
    "    for country in df['country'].unique():\n",
    "        df_country = df[df['country'] == country].sort_values('year')\n",
    "\n",
    "        X_country = df_country[features].values.astype(np.float32)\n",
    "        y_country = df_country[target].values.astype(np.float32)\n",
    "        years_country = df_country['year'].values\n",
    "\n",
    "        if len(X_country) > look_back:\n",
    "            for i in range(len(X_country) - look_back):\n",
    "                X_seq.append(X_country[i:(i + look_back)])\n",
    "                y_seq.append(y_country[i + look_back])\n",
    "                years.append(years_country[i + look_back])\n",
    "                countries.append(country)\n",
    "\n",
    "    return np.array(X_seq, dtype=np.float32), np.array(y_seq, dtype=np.float32), np.array(years), np.array(countries)\n",
    "\n",
    "\n",
    "# ---- Modelos ----\n",
    "def train_random_forest(X_train, y_train, X_test, y_test):\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    return y_test, rf.predict(X_test)\n",
    "\n",
    "def train_xgboost(X_train, y_train, X_test, y_test):\n",
    "    model = xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return y_test, model.predict(X_test)\n",
    "\n",
    "def train_lstm(X_train, y_train, X_test, y_test, look_back):\n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    y_train = np.asarray(y_train, dtype=np.float32)\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    y_test = np.asarray(y_test, dtype=np.float32)\n",
    "\n",
    "    if X_train.shape[0] == 0 or X_test.shape[0] == 0:\n",
    "        return None, None\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(50, activation='relu', input_shape=(look_back, X_train.shape[2])),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=16, verbose=0)\n",
    "\n",
    "    return y_test, model.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "def train_prophet(df, train_years, test_years, target):\n",
    "    prophet_df = df[['year', target]].rename(columns={'year': 'ds', target: 'y'})\n",
    "    prophet_train = prophet_df[prophet_df['ds'].isin(train_years)]\n",
    "    prophet_test = prophet_df[prophet_df['ds'].isin(test_years)]\n",
    "\n",
    "    m = Prophet(yearly_seasonality=True, daily_seasonality=False)\n",
    "    m.fit(prophet_train)\n",
    "    forecast = m.predict(prophet_test[['ds']])\n",
    "\n",
    "    return prophet_test['y'].values, forecast['yhat'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0579f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 1/5 =====\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 15:38:53.306873: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-11 15:38:53.463338: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-11 15:38:57.283884: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "15:38:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:38:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 2/5 =====\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 15:38:58.612926: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-11 15:38:58.761994: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-11 15:39:04.298596: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "15:39:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:39:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 3/5 =====\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 15:39:05.673273: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-11 15:39:05.821698: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-11 15:39:13.140203: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "15:39:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:39:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 4/5 =====\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 15:39:16.162846: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-11 15:39:16.321206: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-11 15:39:25.688516: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "15:39:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:39:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 5/5 =====\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 15:39:27.241992: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-09-11 15:39:27.395695: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n",
      "2025-09-11 15:39:38.579410: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "15:39:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:39:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 4. EJECUCIÓN DE MODELOS CON CROSS-VALIDATION\n",
    "# =============================================================================\n",
    "results = {'Prophet': [], 'RandomForest': [], 'XGBoost': [], 'LSTM': []}\n",
    "\n",
    "# Features numéricas para LSTM\n",
    "features_lstm = df_featured.select_dtypes(include=np.number).columns.tolist()\n",
    "features_lstm = [col for col in features_lstm if col != TARGET]\n",
    "\n",
    "look_back = 3\n",
    "X_seq, y_seq, years_seq, countries_seq = create_lstm_sequences_global(\n",
    "    df_featured, features_lstm, TARGET, look_back\n",
    ")\n",
    "\n",
    "unique_years = df_featured['year'].unique()\n",
    "unique_years.sort()\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(unique_years)):\n",
    "    print(f\"\\n===== FOLD {fold+1}/{n_splits} =====\")\n",
    "\n",
    "    train_years = [unique_years[i] for i in train_idx]\n",
    "    test_years = [unique_years[i] for i in test_idx]\n",
    "\n",
    "    # === Random Forest / XGBoost ===\n",
    "    mask_train = df_featured['year'].isin(train_years)\n",
    "    mask_test = df_featured['year'].isin(test_years)\n",
    "\n",
    "    X_train_tab = X.loc[mask_train].select_dtypes(include=np.number)\n",
    "    y_train_tab = y.loc[mask_train]\n",
    "    X_test_tab = X.loc[mask_test].select_dtypes(include=np.number)\n",
    "    y_test_tab = y.loc[mask_test]\n",
    "\n",
    "    imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_train_tab = scaler.fit_transform(imputer.fit_transform(X_train_tab))\n",
    "    X_test_tab = scaler.transform(imputer.transform(X_test_tab))\n",
    "\n",
    "    y_true_rf, y_pred_rf = train_random_forest(X_train_tab, y_train_tab, X_test_tab, y_test_tab)\n",
    "    results['RandomForest'].append((y_true_rf, y_pred_rf))\n",
    "\n",
    "    y_true_xgb, y_pred_xgb = train_xgboost(X_train_tab, y_train_tab, X_test_tab, y_test_tab)\n",
    "    results['XGBoost'].append((y_true_xgb, y_pred_xgb))\n",
    "\n",
    "    # === LSTM ===\n",
    "    mask_train_lstm = np.isin(years_seq, train_years)\n",
    "    mask_test_lstm = np.isin(years_seq, test_years)\n",
    "\n",
    "    X_train_lstm, y_train_lstm = X_seq[mask_train_lstm], y_seq[mask_train_lstm]\n",
    "    X_test_lstm, y_test_lstm = X_seq[mask_test_lstm], y_seq[mask_test_lstm]\n",
    "\n",
    "    y_true_lstm, y_pred_lstm = train_lstm(X_train_lstm, y_train_lstm, X_test_lstm, y_test_lstm, look_back)\n",
    "    if y_true_lstm is not None:\n",
    "        results['LSTM'].append((y_true_lstm, y_pred_lstm))\n",
    "    else:\n",
    "        results['LSTM'].append(([], []))\n",
    "\n",
    "    # === Prophet ===\n",
    "    try:\n",
    "        y_true_prophet, y_pred_prophet = train_prophet(df_featured, train_years, test_years, TARGET)\n",
    "        results['Prophet'].append((y_true_prophet, y_pred_prophet))\n",
    "    except Exception as e:\n",
    "        results['Prophet'].append(([], []))\n",
    "        print(f\"Prophet falló en fold {fold+1}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da6e159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Resultados finales ===\n",
      "\n",
      "Prophet:\n",
      "  MAE: 29660934.7101\n",
      "  RMSE: 69381350.3311\n",
      "  R2: -0.0035\n",
      "  MAPE: 36026434878106.0156\n",
      "\n",
      "RandomForest:\n",
      "  MAE: 7177462.2481\n",
      "  RMSE: 27314627.1085\n",
      "  R2: 0.8203\n",
      "  MAPE: 253306563716.9294\n",
      "\n",
      "XGBoost:\n",
      "  MAE: 6560130.4319\n",
      "  RMSE: 24589128.7395\n",
      "  R2: 0.8219\n",
      "  MAPE: 459248271655.9100\n",
      "\n",
      "LSTM:\n",
      "  MAE: 5699076.1000\n",
      "  RMSE: 13458134.1243\n",
      "  R2: 0.8699\n",
      "  MAPE: 6765589545011.7100\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 5. EVALUACIÓN DE MÉTRICAS\n",
    "# =============================================================================\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    if len(y_true) == 0 or len(y_pred) == 0:\n",
    "        return None\n",
    "    return {\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"MAPE\": np.mean(np.abs((y_true - y_pred) / (y_true + 1e-6))) * 100  # evitar div/0\n",
    "    }\n",
    "\n",
    "summary = {}\n",
    "print(\"\\n=== Resultados finales ===\")\n",
    "for model, folds in results.items():\n",
    "    fold_metrics = []\n",
    "    for (y_true, y_pred) in folds:\n",
    "        m = compute_metrics(np.array(y_true), np.array(y_pred))\n",
    "        if m:\n",
    "            fold_metrics.append(m)\n",
    "    if fold_metrics:\n",
    "        avg_metrics = {k: np.mean([fm[k] for fm in fold_metrics]) for k in fold_metrics[0]}\n",
    "        summary[model] = avg_metrics\n",
    "        print(f\"\\n{model}:\")\n",
    "        for k, v in avg_metrics.items():\n",
    "            print(f\"  {k}: {v:.4f}\")\n",
    "    else:\n",
    "        print(f\"\\n{model}: sin resultados\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6ff7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
